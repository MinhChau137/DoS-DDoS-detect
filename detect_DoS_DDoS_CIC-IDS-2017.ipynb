{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66d9dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Using cached kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->kagglehub) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Using cached kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.12\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b18f8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec79e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\solarmainframe\\ids-intrusion-csv\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# import bộ dữ liệu CICIDS từ kaggle về\n",
    "# tôi sử dụng bộ dữ liệu IDS 2018 Intrusion CSVs (CSE-CIC-IDS2018)\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version to the current directory\n",
    "path = kagglehub.dataset_download(\"solarmainframe/ids-intrusion-csv\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fda7aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-14-2018.csv\n",
      "02-15-2018.csv\n",
      "02-16-2018.csv\n",
      "02-20-2018.csv\n",
      "02-21-2018.csv\n",
      "02-22-2018.csv\n",
      "02-23-2018.csv\n",
      "02-28-2018.csv\n",
      "03-01-2018.csv\n",
      "03-02-2018.csv\n"
     ]
    }
   ],
   "source": [
    "#display the files in path\n",
    "import os\n",
    "for file in os.listdir(path):\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:38</td>\n",
       "      <td>141385</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>553</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49684</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:38</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:40</td>\n",
       "      <td>279824</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1086</td>\n",
       "      <td>10527.0</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:40</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:41</td>\n",
       "      <td>274016</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>1285</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
       "0       443         6  02/03/2018 08:47:38         141385             9   \n",
       "1     49684         6  02/03/2018 08:47:38            281             2   \n",
       "2       443         6  02/03/2018 08:47:40         279824            11   \n",
       "3       443         6  02/03/2018 08:47:40            132             2   \n",
       "4       443         6  02/03/2018 08:47:41         274016             9   \n",
       "\n",
       "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
       "0             7              553           3773.0              202   \n",
       "1             1               38              0.0               38   \n",
       "2            15             1086          10527.0              385   \n",
       "3             0                0              0.0                0   \n",
       "4            13             1285           6141.0              517   \n",
       "\n",
       "   Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0                0  ...                20          0.0         0.0   \n",
       "1                0  ...                20          0.0         0.0   \n",
       "2                0  ...                20          0.0         0.0   \n",
       "3                0  ...                20          0.0         0.0   \n",
       "4                0  ...                20          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
       "0         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "1         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "2         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "3         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "4         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(os.path.join(path, \"03-02-2018.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db53b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Benign    762384\n",
       "Bot       286191\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display data colume Label\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419174c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\chethuhn\\network-intrusion-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# tải bộ dữ liệu CIC-IDS- 2017\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path_2017 = kagglehub.dataset_download(\"chethuhn/network-intrusion-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c94a5e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "Monday-WorkingHours.pcap_ISCX.csv\n",
      "Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "Wednesday-workingHours.pcap_ISCX.csv\n"
     ]
    }
   ],
   "source": [
    "#display the files in path\n",
    "import os\n",
    "for file in os.listdir(path_2017):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7ff934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54865</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55054</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55055</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46236</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54863</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830738</th>\n",
       "      <td>53</td>\n",
       "      <td>32215</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>152</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830739</th>\n",
       "      <td>53</td>\n",
       "      <td>324</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>362</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830740</th>\n",
       "      <td>58030</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>21.92031</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830741</th>\n",
       "      <td>53</td>\n",
       "      <td>1048635</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>192</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830742</th>\n",
       "      <td>53</td>\n",
       "      <td>94939</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>226</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2830743 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0                    54865               3                   2   \n",
       "1                    55054             109                   1   \n",
       "2                    55055              52                   1   \n",
       "3                    46236              34                   1   \n",
       "4                    54863               3                   2   \n",
       "...                    ...             ...                 ...   \n",
       "2830738                 53           32215                   4   \n",
       "2830739                 53             324                   2   \n",
       "2830740              58030              82                   2   \n",
       "2830741                 53         1048635                   6   \n",
       "2830742                 53           94939                   4   \n",
       "\n",
       "          Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                              0                           12   \n",
       "1                              1                            6   \n",
       "2                              1                            6   \n",
       "3                              1                            6   \n",
       "4                              0                           12   \n",
       "...                          ...                          ...   \n",
       "2830738                        2                          112   \n",
       "2830739                        2                           84   \n",
       "2830740                        1                           31   \n",
       "2830741                        2                          192   \n",
       "2830742                        2                          188   \n",
       "\n",
       "          Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                                   0                       6   \n",
       "1                                   6                       6   \n",
       "2                                   6                       6   \n",
       "3                                   6                       6   \n",
       "4                                   0                       6   \n",
       "...                               ...                     ...   \n",
       "2830738                           152                      28   \n",
       "2830739                           362                      42   \n",
       "2830740                             6                      31   \n",
       "2830741                           256                      32   \n",
       "2830742                           226                      47   \n",
       "\n",
       "          Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
       "0                             6                      6.0   \n",
       "1                             6                      6.0   \n",
       "2                             6                      6.0   \n",
       "3                             6                      6.0   \n",
       "4                             6                      6.0   \n",
       "...                         ...                      ...   \n",
       "2830738                      28                     28.0   \n",
       "2830739                      42                     42.0   \n",
       "2830740                       0                     15.5   \n",
       "2830741                      32                     32.0   \n",
       "2830742                      47                     47.0   \n",
       "\n",
       "          Fwd Packet Length Std  ...   min_seg_size_forward  Active Mean  \\\n",
       "0                       0.00000  ...                     20          0.0   \n",
       "1                       0.00000  ...                     20          0.0   \n",
       "2                       0.00000  ...                     20          0.0   \n",
       "3                       0.00000  ...                     20          0.0   \n",
       "4                       0.00000  ...                     20          0.0   \n",
       "...                         ...  ...                    ...          ...   \n",
       "2830738                 0.00000  ...                     20          0.0   \n",
       "2830739                 0.00000  ...                     20          0.0   \n",
       "2830740                21.92031  ...                     32          0.0   \n",
       "2830741                 0.00000  ...                     20          0.0   \n",
       "2830742                 0.00000  ...                     20          0.0   \n",
       "\n",
       "          Active Std   Active Max   Active Min  Idle Mean   Idle Std  \\\n",
       "0                0.0            0            0        0.0        0.0   \n",
       "1                0.0            0            0        0.0        0.0   \n",
       "2                0.0            0            0        0.0        0.0   \n",
       "3                0.0            0            0        0.0        0.0   \n",
       "4                0.0            0            0        0.0        0.0   \n",
       "...              ...          ...          ...        ...        ...   \n",
       "2830738          0.0            0            0        0.0        0.0   \n",
       "2830739          0.0            0            0        0.0        0.0   \n",
       "2830740          0.0            0            0        0.0        0.0   \n",
       "2830741          0.0            0            0        0.0        0.0   \n",
       "2830742          0.0            0            0        0.0        0.0   \n",
       "\n",
       "          Idle Max   Idle Min   Label  \n",
       "0                0          0  BENIGN  \n",
       "1                0          0  BENIGN  \n",
       "2                0          0  BENIGN  \n",
       "3                0          0  BENIGN  \n",
       "4                0          0  BENIGN  \n",
       "...            ...        ...     ...  \n",
       "2830738          0          0  BENIGN  \n",
       "2830739          0          0  BENIGN  \n",
       "2830740          0          0  BENIGN  \n",
       "2830741          0          0  BENIGN  \n",
       "2830742          0          0  BENIGN  \n",
       "\n",
       "[2830743 rows x 79 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge tất các file csv trong thư mục path_2017\n",
    "import glob\n",
    "import pandas as pd\n",
    "# Get all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(path_2017, \"*.csv\"))\n",
    "# Read and concatenate all CSV files into a single DataFrame\n",
    "df_2017 = pd.concat((pd.read_csv(file) for file in csv_files), ignore_index=True)\n",
    "# Display the first few rows of the DataFrame\n",
    "df_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3122f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f9d1f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: [' Destination Port', ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets', 'Total Length of Fwd Packets', ' Total Length of Bwd Packets', ' Fwd Packet Length Max', ' Fwd Packet Length Min', ' Fwd Packet Length Mean', ' Fwd Packet Length Std', 'Bwd Packet Length Max', ' Bwd Packet Length Min', ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size', ' Avg Fwd Segment Size', ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward', ' Init_Win_bytes_backward', ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min', ' Label']\n"
     ]
    }
   ],
   "source": [
    "# get all name of columns\n",
    "columns_2017 = df_2017.columns.tolist()\n",
    "# Display the columns\n",
    "print(\"Columns in the dataset:\", columns_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06257ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "BENIGN                        2273097\n",
      "DoS Hulk                       231073\n",
      "PortScan                       158930\n",
      "DDoS                           128027\n",
      "DoS GoldenEye                   10293\n",
      "FTP-Patator                      7938\n",
      "SSH-Patator                      5897\n",
      "DoS slowloris                    5796\n",
      "DoS Slowhttptest                 5499\n",
      "Bot                              1966\n",
      "Web Attack � Brute Force         1507\n",
      "Web Attack � XSS                  652\n",
      "Infiltration                       36\n",
      "Web Attack � Sql Injection         21\n",
      "Heartbleed                         11\n",
      "Name: count, dtype: int64\n",
      "New class counts:\n",
      "Label_grp\n",
      "BENIGN      2273097\n",
      "DoS          252661\n",
      "PortScan     158930\n",
      "DDoS         128027\n",
      "Other         18028\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_2017.columns = df_2017.columns.str.strip()\n",
    "print(df_2017['Label'].value_counts())\n",
    "df_2017['Label'] = df_2017['Label'].str.strip()\n",
    "\n",
    "mapping = {\n",
    "    'BENIGN': 'BENIGN',\n",
    "    'DDoS': 'DDoS',\n",
    "    'PortScan': 'PortScan',\n",
    "    'DoS GoldenEye': 'DoS',\n",
    "    'DoS Hulk': 'DoS',\n",
    "    'DoS Slowhttptest': 'DoS',\n",
    "    'DoS slowloris': 'DoS'\n",
    "}\n",
    "df_2017['Label_grp'] = df_2017['Label'].map(mapping).fillna('Other')\n",
    "print(\"New class counts:\")\n",
    "print(df_2017['Label_grp'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79747f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "counts = df_2017['Label_grp'].value_counts()\n",
    "plt.figure()\n",
    "plt.bar(counts.index, counts.values)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Merged Class Distribution (pre‐undersample)\")\n",
    "plt.ylabel(\"Flows\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "424fa8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of downsampled DataFrame: (418028, 80)\n",
      "New class counts after undersampling:\n",
      "Label_grp\n",
      "BENIGN      100000\n",
      "DDoS        100000\n",
      "PortScan    100000\n",
      "DoS         100000\n",
      "Other        18028\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# vì số lượng mẫu benign và mẫu bất thường chênh lêch quá lớn nên tôi sẽ tiến hành undersample với số lượng mẫu benign, DoS, DDoS, PortScan là 100.000 mẫu\n",
    "from sklearn.utils import resample\n",
    "\n",
    "max_samples = 100000\n",
    "df_label_downsampled = []\n",
    "for label in df_2017['Label_grp'].unique():\n",
    "    df_label = df_2017[df_2017['Label_grp'] == label]\n",
    "    if len(df_label) > max_samples:\n",
    "        df_label = resample(df_label, n_samples=max_samples, random_state=42)\n",
    "    df_label_downsampled.append(df_label)\n",
    "# Concatenate all downsampled DataFrames\n",
    "df_downsampled = pd.concat(df_label_downsampled, ignore_index=True)\n",
    "# Display the shape of the downsampled DataFrame\n",
    "print(\"Shape of downsampled DataFrame:\", df_downsampled.shape)\n",
    "# New class counts after undersampling:\n",
    "print(\"New class counts after undersampling:\")\n",
    "print(df_downsampled['Label_grp'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5df8d26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>188</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60145</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>140894</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>157</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>21072988</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1919</td>\n",
       "      <td>5389</td>\n",
       "      <td>777</td>\n",
       "      <td>0</td>\n",
       "      <td>127.933333</td>\n",
       "      <td>271.190620</td>\n",
       "      <td>...</td>\n",
       "      <td>182895.0</td>\n",
       "      <td>124331.99955</td>\n",
       "      <td>270811</td>\n",
       "      <td>94979</td>\n",
       "      <td>10018510.0</td>\n",
       "      <td>71436.169676</td>\n",
       "      <td>10069023</td>\n",
       "      <td>9967997</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418023</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418024</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418025</th>\n",
       "      <td>80</td>\n",
       "      <td>99307967</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>361</td>\n",
       "      <td>11595</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>45.125000</td>\n",
       "      <td>127.632774</td>\n",
       "      <td>...</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>99300000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99300000</td>\n",
       "      <td>99300000</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418026</th>\n",
       "      <td>80</td>\n",
       "      <td>990</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418027</th>\n",
       "      <td>80</td>\n",
       "      <td>126405</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>378</td>\n",
       "      <td>11595</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>218.238402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418028 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Destination Port  Flow Duration  Total Fwd Packets  \\\n",
       "0                    443              3                  2   \n",
       "1                     53            193                  2   \n",
       "2                  60145             31                  1   \n",
       "3                     53         140894                  1   \n",
       "4                    443       21072988                 15   \n",
       "...                  ...            ...                ...   \n",
       "418023                80              3                  2   \n",
       "418024                80              4                  2   \n",
       "418025                80       99307967                  8   \n",
       "418026                80            990                  2   \n",
       "418027                80         126405                  3   \n",
       "\n",
       "        Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                            0                           12   \n",
       "1                            2                           60   \n",
       "2                            1                            0   \n",
       "3                            1                           64   \n",
       "4                           12                         1919   \n",
       "...                        ...                          ...   \n",
       "418023                       0                            0   \n",
       "418024                       0                            0   \n",
       "418025                       6                          361   \n",
       "418026                       0                            0   \n",
       "418027                       5                          378   \n",
       "\n",
       "        Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
       "0                                 0                      6   \n",
       "1                               188                     30   \n",
       "2                                 0                      0   \n",
       "3                               157                     64   \n",
       "4                              5389                    777   \n",
       "...                             ...                    ...   \n",
       "418023                            0                      0   \n",
       "418024                            0                      0   \n",
       "418025                        11595                    361   \n",
       "418026                            0                      0   \n",
       "418027                        11595                    378   \n",
       "\n",
       "        Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
       "0                           6                6.000000               0.000000   \n",
       "1                          30               30.000000               0.000000   \n",
       "2                           0                0.000000               0.000000   \n",
       "3                          64               64.000000               0.000000   \n",
       "4                           0              127.933333             271.190620   \n",
       "...                       ...                     ...                    ...   \n",
       "418023                      0                0.000000               0.000000   \n",
       "418024                      0                0.000000               0.000000   \n",
       "418025                      0               45.125000             127.632774   \n",
       "418026                      0                0.000000               0.000000   \n",
       "418027                      0              126.000000             218.238402   \n",
       "\n",
       "        ...  Active Mean    Active Std  Active Max  Active Min   Idle Mean  \\\n",
       "0       ...          0.0       0.00000           0           0         0.0   \n",
       "1       ...          0.0       0.00000           0           0         0.0   \n",
       "2       ...          0.0       0.00000           0           0         0.0   \n",
       "3       ...          0.0       0.00000           0           0         0.0   \n",
       "4       ...     182895.0  124331.99955      270811       94979  10018510.0   \n",
       "...     ...          ...           ...         ...         ...         ...   \n",
       "418023  ...          0.0       0.00000           0           0         0.0   \n",
       "418024  ...          0.0       0.00000           0           0         0.0   \n",
       "418025  ...        995.0       0.00000         995         995  99300000.0   \n",
       "418026  ...          0.0       0.00000           0           0         0.0   \n",
       "418027  ...          0.0       0.00000           0           0         0.0   \n",
       "\n",
       "            Idle Std  Idle Max  Idle Min     Label  Label_grp  \n",
       "0           0.000000         0         0    BENIGN     BENIGN  \n",
       "1           0.000000         0         0    BENIGN     BENIGN  \n",
       "2           0.000000         0         0    BENIGN     BENIGN  \n",
       "3           0.000000         0         0    BENIGN     BENIGN  \n",
       "4       71436.169676  10069023   9967997    BENIGN     BENIGN  \n",
       "...              ...       ...       ...       ...        ...  \n",
       "418023      0.000000         0         0  DoS Hulk        DoS  \n",
       "418024      0.000000         0         0  DoS Hulk        DoS  \n",
       "418025      0.000000  99300000  99300000  DoS Hulk        DoS  \n",
       "418026      0.000000         0         0  DoS Hulk        DoS  \n",
       "418027      0.000000         0         0  DoS Hulk        DoS  \n",
       "\n",
       "[418028 rows x 80 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14d8c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled dataset saved to C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\chethuhn\\network-intrusion-dataset\\versions\\1\\undersampled_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# save the undersampled DataFrame to a new CSV file\n",
    "output_file = os.path.join(path_2017, \"undersampled_dataset.csv\")\n",
    "df_downsampled.to_csv(output_file, index=False)\n",
    "print(f\"Undersampled dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "017b30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# đọc file downsampled_dataset.csv\n",
    "df_downsampled = pd.read_csv(os.path.join(path_2017, \"undersampled_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccfee023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>188</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60145</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>140894</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>157</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>21072988</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1919</td>\n",
       "      <td>5389</td>\n",
       "      <td>777</td>\n",
       "      <td>0</td>\n",
       "      <td>127.933333</td>\n",
       "      <td>271.190620</td>\n",
       "      <td>...</td>\n",
       "      <td>182895.0</td>\n",
       "      <td>124331.99955</td>\n",
       "      <td>270811</td>\n",
       "      <td>94979</td>\n",
       "      <td>10018510.0</td>\n",
       "      <td>71436.169676</td>\n",
       "      <td>10069023</td>\n",
       "      <td>9967997</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418023</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418024</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418025</th>\n",
       "      <td>80</td>\n",
       "      <td>99307967</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>361</td>\n",
       "      <td>11595</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>45.125000</td>\n",
       "      <td>127.632774</td>\n",
       "      <td>...</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>99300000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99300000</td>\n",
       "      <td>99300000</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418026</th>\n",
       "      <td>80</td>\n",
       "      <td>990</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418027</th>\n",
       "      <td>80</td>\n",
       "      <td>126405</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>378</td>\n",
       "      <td>11595</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>218.238402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418028 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Destination Port  Flow Duration  Total Fwd Packets  \\\n",
       "0                    443              3                  2   \n",
       "1                     53            193                  2   \n",
       "2                  60145             31                  1   \n",
       "3                     53         140894                  1   \n",
       "4                    443       21072988                 15   \n",
       "...                  ...            ...                ...   \n",
       "418023                80              3                  2   \n",
       "418024                80              4                  2   \n",
       "418025                80       99307967                  8   \n",
       "418026                80            990                  2   \n",
       "418027                80         126405                  3   \n",
       "\n",
       "        Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                            0                           12   \n",
       "1                            2                           60   \n",
       "2                            1                            0   \n",
       "3                            1                           64   \n",
       "4                           12                         1919   \n",
       "...                        ...                          ...   \n",
       "418023                       0                            0   \n",
       "418024                       0                            0   \n",
       "418025                       6                          361   \n",
       "418026                       0                            0   \n",
       "418027                       5                          378   \n",
       "\n",
       "        Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
       "0                                 0                      6   \n",
       "1                               188                     30   \n",
       "2                                 0                      0   \n",
       "3                               157                     64   \n",
       "4                              5389                    777   \n",
       "...                             ...                    ...   \n",
       "418023                            0                      0   \n",
       "418024                            0                      0   \n",
       "418025                        11595                    361   \n",
       "418026                            0                      0   \n",
       "418027                        11595                    378   \n",
       "\n",
       "        Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
       "0                           6                6.000000               0.000000   \n",
       "1                          30               30.000000               0.000000   \n",
       "2                           0                0.000000               0.000000   \n",
       "3                          64               64.000000               0.000000   \n",
       "4                           0              127.933333             271.190620   \n",
       "...                       ...                     ...                    ...   \n",
       "418023                      0                0.000000               0.000000   \n",
       "418024                      0                0.000000               0.000000   \n",
       "418025                      0               45.125000             127.632774   \n",
       "418026                      0                0.000000               0.000000   \n",
       "418027                      0              126.000000             218.238402   \n",
       "\n",
       "        ...  Active Mean    Active Std  Active Max  Active Min   Idle Mean  \\\n",
       "0       ...          0.0       0.00000           0           0         0.0   \n",
       "1       ...          0.0       0.00000           0           0         0.0   \n",
       "2       ...          0.0       0.00000           0           0         0.0   \n",
       "3       ...          0.0       0.00000           0           0         0.0   \n",
       "4       ...     182895.0  124331.99955      270811       94979  10018510.0   \n",
       "...     ...          ...           ...         ...         ...         ...   \n",
       "418023  ...          0.0       0.00000           0           0         0.0   \n",
       "418024  ...          0.0       0.00000           0           0         0.0   \n",
       "418025  ...        995.0       0.00000         995         995  99300000.0   \n",
       "418026  ...          0.0       0.00000           0           0         0.0   \n",
       "418027  ...          0.0       0.00000           0           0         0.0   \n",
       "\n",
       "            Idle Std  Idle Max  Idle Min     Label  Label_grp  \n",
       "0           0.000000         0         0    BENIGN     BENIGN  \n",
       "1           0.000000         0         0    BENIGN     BENIGN  \n",
       "2           0.000000         0         0    BENIGN     BENIGN  \n",
       "3           0.000000         0         0    BENIGN     BENIGN  \n",
       "4       71436.169676  10069023   9967997    BENIGN     BENIGN  \n",
       "...              ...       ...       ...       ...        ...  \n",
       "418023      0.000000         0         0  DoS Hulk        DoS  \n",
       "418024      0.000000         0         0  DoS Hulk        DoS  \n",
       "418025      0.000000  99300000  99300000  DoS Hulk        DoS  \n",
       "418026      0.000000         0         0  DoS Hulk        DoS  \n",
       "418027      0.000000         0         0  DoS Hulk        DoS  \n",
       "\n",
       "[418028 rows x 80 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7d41981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQiUlEQVR4nO3dCbxN5fv//8uQsUwZK1PIPESRDBFRqQiVKEIakKkylEjDxxQhlSZDfRKpCBnToEIiIiJFUT6GyjwP6/943//v2r99jnNYR2fa+7yej8fm7L3X2fs+a6+91rXu+7qvlc7zPM8AAABwTunPvQgAAACEwAkAACAgAicAAICACJwAAAACInACAAAIiMAJAAAgIAInAACAgAicAAAAAiJwAgAACIjACUiAp59+2tKlS5eor/nbb7+515w4caJFunr16rlbctA60+cR+7P566+/kuX9ixUrZvfdd5+llGHDhlmZMmXs9OnTKdaG1E7fKW0T+o7hzO9MUOvXr7eMGTPajz/+mCTtijQETkjUHZRuX3/99RnP68o+hQsXds/fcsstllZ88cUX1rx5cytYsKBlypTJ8ufPb7feeqt99NFHltopKPA/U90uvPBCu/zyy61ly5b24YcfJtoBe8mSJW5nvnfvXkttUmvb9u/fb0OHDrU+ffpY+vQpuxufPHmyjRo1KkXbgKRVrlw5a9KkiQ0YMCClm5IqZEzpBiC6ZMmSxe1Ia9euHePxL7/80v744w/LnDmzpRUDBw60Z555xkqVKmUPPvigFS1a1P7++2+bM2eOtWjRwt59911r3bq1pWb6vN58803385EjR+z333+3WbNmueBJPUsff/yx5ciRI7T8ggULzis4GTRokAvUcuXKFfj31B6dBSels7Vt48aNKRa0jB8/3k6ePGl33323pTR939UT0aNHj5RuCpLQQw89ZDfffLP9+uuvVqJECUvLCJyQqPTFmjZtmo0ZMybGQU0712rVqiXqMIp6sY4ePWpZs2a11OaDDz5wQZMCDP3tF1xwQei5xx9/3ObPn28nTpyw1E6f4T333BPjseeee86GDBli/fr1s06dOtnUqVNDz6lXLSmpl+v48eMuQNctJaXkScCECRPstttuS/F1kNYcOnTIsmfPbmlRw4YNLXfu3DZp0iS3b0vLGKpDotIZsHpVFi5cGHpMBzoFEvH1ruhgqK7+8uXLuwNBgQIFXA/Nnj17zsgp0TCfgo6rrrrKBUyvvfaae049ITqQaKem4bCePXu65TTEpOGycN9++63deOONljNnTsuWLZtdd9119s0335zRLg05Xn311a5NOsPy3yuIp556yvLkyeN6BsKDJl/jxo3POmS5Zs0a18uhoTG9v4b6OnTo4NZtuAMHDrgzfa0bHcj1t99www32/fffh5bZtGmT6+HSa+i1LrvsMmvVqpXt27fPzlffvn2tUaNGLkj++eefz5rj9NJLL7nPVutaO159dgomRcNgCiSlePHioWFBPydFP3ft2tX1zuk19DfOmzfvrPkaCs7vvPNO1xN28cUXW/fu3V2AHSSnLPw1z9W2uHKcNm/ebHfccYf77PX3XnPNNfbJJ5/EWEbbo17n/ffft+eff959HvpcGjRoYL/88ss51/2WLVvc9qEDWTj/73rhhRfsxRdfdD2c+o5o+44rN+Wzzz6zOnXquO+MetOaNm1qP/30U4K2L33W+vv0/fPXj5Y9nzzBuPKR/O+8vovVq1d360nfibfffvuM31+3bp1df/317m/WOlWAH99w8ty5c0N/+0UXXeSGofT74fTZanhaPSw6IdRybdq0CfydUnCr9midad1puOvVV189oy3+36jtwt+vVaxYMbTf0rC+7ut9dPK5atWqONupbU/7Ff1Nl1xyiQtudHJ5Ln/++afbt2i/q3bqe6b9Vmzaj/m9zGkdPU5IVNoJ1KxZ09577z276aabQjsp7VC0Y1FPVGwKkrTTbN++vXXr1s0dGMaOHet2EApowgMPDY8oONPvqLejdOnS7ixQO6j//e9/7iCpnZkOzJ9//nmcBwu1SzsgDaVpqMXfwX311Vdu5yxr1651gUG+fPncjl7DIlpeO5dz0U51w4YNbmekne35UOCpHaHWif4e7dRff/119/+yZctCBx51nysoVXChHbMCKx1kdACsWrWqC1q1Mz127Jg98sgj7rW0o5w9e7bL21HweL7uvfdeNzSntl5xxRVxLvPGG2+4z1Q9b34Ao4O+glcF0sr/UuCl7UUH+7x587rf03oP/8wUZOhv1PPnOjAraNIygwcPdutK25yC8LgOtmcTpG3hdu7caddee60dPnzY/c0K2nR2roBen9Htt98eY3n12mn7e+yxx9z3Q8neOjBr3Zxr+FD0+cZFf6cCni5durj1PXr0aLd9a5v2t99PP/3UfQ8UhGj71rCnAtxatWq5oMhfx+favp588knXdg3Dax2JDuKJScGktp+OHTtau3bt3EFdwYK+wzrIy44dO6x+/frue6qgXsGDvi9x9Ua/88477nX0vVCemD4vBTRKL9A+J3z70utpOT2ngFTBcNDvlF5T7dPnr55bDXF37tzZBXP6bGL/jfo+aL+mHl69l3Ihx40bZ0888YT7PdE2re079jDxqVOn3MmgAnVtRzq50P5K7T9b75C2Wf2Of4KibVv7a61r5dHFHn7VOv/444/dc+FD9GmOBySCCRMm6NTG++6777yxY8d6F110kXf48GH33B133OHVr1/f/Vy0aFGvSZMmod/76quv3O+9++67MV5v3rx5Zzyu39Vjei7ciBEj3OMzZswIPXbkyBGvTJky7vHPP//cPXb69GmvVKlSXuPGjd3PPrWzePHi3g033BB6rFmzZl6WLFm833//PfTY+vXrvQwZMrjXPJuPP/7YLfPiiy8GWndbtmxxy2sdhrcptvfee88tt3jx4tBjOXPm9Lp06RLva69atcr9zrRp07yEateunZc9e/ZzvnbPnj1Dj1133XXu5mvatKlXvnz5s77P8OHD3etoPcSmx9OnT++tW7cuzucGDhwYuq+f9dhtt90WY7nOnTu7x3/44Yd413d8r3m2tml71Dry9ejRwy2rbdp34MABt20VK1bMO3XqlHtM26OWK1u2rHfs2LHQsqNHj3aPr1279qzrq3///m45vXY4/+/KmjWr98cff4Qe//bbb8/4nKpUqeLlz5/f+/vvv0OPaf1oXbdt2zbw9iX6PmtdBOV/TvHtQ8LXtf+dD9/md+3a5WXOnNl79NFHz1j3+lvDl1P7w19T6yxXrlxep06dYrz3jh073LLhj+uz1e/27dv3vL5TcX2Hte+5/PLLYzzm/41LliwJPTZ//vzQZxm+D3rttddi7NPC2/nII4+EHtP+TZ9LpkyZvN27d8e7fXfs2NErVKiQ99dff8VoU6tWrdz6iP03TJ48+Yz1nBYxVIdEpzMincHqDExnvvo/vmE6DfXoDE3d/xpi8W86s9GZa+xeIw2Z6GwvnM6uLr30Undm51O3tnqkwq1evdr1BqktOnP230s9VhomWbx4sTsb1NmbhvmaNWtmRYoUCf1+2bJlz3jvuOhsTM63t0nCz5TVa6B26sxQwofhNMSiHort27fH+Tr+2a/+Hp1ZJya/Z0GfcXzUPvVGfPfdd+f9PhpqUm9HULHP5tUrIErKT0p6ffVYhk+M0Dp64IEH3PCTpnSHU29ieE6Yho5EPY1no21XPRjx9exou9X3wac21ahRI/T3q2dW3wX12mhI0VepUiX3PQxfT+favpKDPnt/3Yh6RdTTHL6e1GZ9P/weY385f2jNp95R9Qqp1zp8f5MhQwa3juLqpX744YfP6zsV/h1Wr5zeR9uy2h17mFx/o3rqfWqLqKcwfB/kPx7XNqIeI5/fg6TeMfUuxkVxlGbHqmdLP4evD+3n1MbwfY1oqF2Sq+RHakXghESnHZbyLzRcpvF5BSLqao+LAhl9QZUHoN8Lvx08eNB27dp1RuAUm/IrlIMUO2+iZMmSZ7yXqJs+9ntp5pi63tWW3bt3u8BPs+Fi0w77XPwu7LMFFOfyzz//uKEtDa1oB6w2+n97+E5X3fLKX1GpBx00NOwSvlPV7/Tq1cv9fRpq0g7x5Zdf/lf5TT59PucKEDVdXgd4tU3rU0FNXPlkZxPXZ342sT83bRsa1kjqWj7aDuPaPhRw+8+HCz8ghh+UYuf2JVRc262GUv2/329HfG31TyaCbF9no+Gz8Ju+U+cj9nry11X4etLfFOT76u8DFJDE3gdo2Dn2/kYBqvKXwgX9Tmk7137QzyHTe2jYTWIvG/tv9IMzrfe4Ho+9jWj71rBrOH/4PL7tXvs5BZEa0oy9LhTUS+z14edMpUvkWnaRhhwnJAn16qjHRztM5VLEN81cPTwKmpT8G5fY+ST/Zgadnyg6fPhwq1KlSpzL6CCvAOrfUFFCUU7Jv+m1Uy6LkpPVVrVL7VceQ3jCq5bT2fj06dPdjl9/m/I2FLD6OWYjRoxwvQvKTdAyyr/x839iHxQSwk84jh2gxj4QKx9DvY7qGdQZ7iuvvOLqwWiafxD/dtZk7J18fDt9BfjJSb0ccTlXQq9yp5S7osD83/RqBhFk+4pPoUKFYtxXLqFfGywh6/9811Nc/O+O8pyUmxRb7PIWSpaOq+TEub5TSihXL7b2BSNHjnQBkHoX1TOmXLDYSevx/Y2J+bfH5rdBOVU6mYyLeiHD+QFb3v/L90urCJyQJJQIq0RH7UjCp6vHpt4AdSUrKfV8D5CaPaRhEO1MwnfKsWco+bVH1CMUe0ZS7GBNbfHPTsMpCDgXnenpTFc7VSXmJjRZVjunRYsWucAivOBcXO3xD1BKHtVNZ4hK2tVsrfADm2bl6Na/f38XkGl9K/FUM4/Olw4+Wt8a3jkbnXHfdddd7qahAyVdq30qZ6Ah1cQ+e9V6Cu+l0nagg4Sf9Ov37MQuahm7R0gS0jZth3FtH5oo4D+fGPzAXJMoYh/Y4ttOlOTu//1+O+Jrqw6K4VPuz7V9xbeOwmfWip/IHb7+w0+o4lr/QelvCvJ99fcBOlk72z4giLN9p5QIrhOwmTNnxuhNimsoMDFo+1ZPYPgkDX+2a3yTKbSfU+CtgDXoutA2lz59+ngng6QVDNUhSShY0KwSde1rDP1sZ7T64j777LNnPKez6iAVm9VVrlkt2kmF5wVpRlc45U1px6kZK/4wU+yua/8sT685Y8YM27p1a+h5zSRSXkMQCnqUi3L//fe7vyM2naWqF+ZsZ5mxzypjV2fWeovd5a8DgqYi+71myreK/f7a2Wvn92961jQjTH+DgqG4hkh8scsn6Kxb+Rz62/w6Vv5BOrGqc2vYJJxmi4l/oFfgrOBAOW3h1BMWW0Lapinry5cvt6VLl4Ye05CXhkJ08EpIntbZ+LkwK1asiPN5bbf6PvjUJuUp+X+/AiH1YmrGX/jfpR5Efab6O4JuX/46imvoVwfj8JvfA+UHL+HrX+tJ7TlfarNO0vS3hn+fY/dk63utz/8///lPnHXU/H3A2QT5TsX1HdY6Uq9bUtFMZJ/eV/c1I1k9X3FRG1VSQb3AcZWriGtdrFy50gXA/2Y2bjSgxwlJJr7u33BKllTPlLq5lbCqEgD6suvsUYnj6rGJLz/Kp9/XTkIJn8oL0g5aO0y/OKB/Rqwdm/ISdADRl1/j+Eqi1UFGZ4LaoepM0Q98NLSkYQqdaWtH6dcj0nT6c1FAoaE6nZlrirPa5lcO1+uqR8mvZRSb2lG3bl2XX6Kdu9qoA5rO9sJpqEbDAlo/lStXdsGqeu+UiK2hBH8qv5JEVVtIZ4n6O9RT5O80z0XL//e//w0Fo+oVUICqdaDp3woKzkafp4ZEdDaufC0Fn/qsVDfHH2ZSQCua2q6SFfr8FWyfb6FBrSdNFNCwpoIYtV9Dx1pHPgW0Cv70v2rn6CAeXo/Kl5C2aRq8X4ZDQzdKvFYwoPbo4JRYVcaVy1KhQgX3WavkRWwaOlWCupKadSBXwK3hvd69e4eW0ZCb2qkgTFPP/XIEOiD6dayCbF/+OlKvsvJ+VPdMy53tZEnbhHph9L4aita2qBID6gEJP1FJCP1t2q71mWsf4Jcj0Hcu/Puq75ZO6FRKQz1n+kz991U9Km2n4QFIXIJ8p/Q36iRB60H7J52o6UROgaeS8xOb9nXar2ifqwRylRTQ36OcqvjKZ4i+A9r36XeUWqHgXvmVSgrXZ62ffdoX6QoQnf+vNEKaltLT+hB95QjOJnY5At/rr7/uVatWzU2/VSmDihUrer179/a2b99+zt+VzZs3u+f0+/ny5XNTlT/88EPXpmXLlp0xnbh58+bexRdf7KY163XvvPNOb9GiRTGW+/LLL12bNKVXU4jHjRsX71Tq+Og1NSVfU78zZszo2nbrrbe6kgW+uKbHazr57bff7qZOa1qwSjpoXYRPJ9ZU9scff9yrXLmyW2cqHaCfX3nllRjrpUOHDl6JEiVceYU8efK40hCffvrpOdvuT3P2b9myZXPT6lu0aOF98MEHoen14WKXI9D06bp164bWtdqhNu/bty/G7z377LPepZde6qbDh08f18/xTYePrxyByka0bNnSrZPcuXN7Xbt2deUpwmmataZia91qOX3+mr4e+zXP1rbY5Qjk119/de+tz03ru3r16t7s2bNjLOOXI4g9nf1sZRJiGzlypHfhhRfGmC7u/75KKKhER+HChd06r1OnTqgUQzhtA7Vq1XLfmRw5crjtUuvOF2T7koMHD3qtW7d2f7PeP0hpgpUrV3o1atRw360iRYq4vye+cgRxfedjb2eyZs0a95jWuz4vfW5vvfVWnOUk9BmoNIA+fy2v7fK+++7zVqxYcc5yHEG/UzNnzvQqVarkltH3ZujQod748eMD/41xbfvhn3Hsdmrba9SokfueFihQwG3Hsb+jcW3fO3fudO+j7eWCCy7wChYs6DVo0MDtk8PNnTvX/f6mTZu8tC6d/knp4A1ICjrTVgVxTYcPn54NRDoN+6jnSb2S6rnxZ08pt0u9SSqqibRBSeoqUhpX+kFiUpkL9d5Pnz7d0jpynBAVYk911rCSLpGi/BuCJkQbDalpeEpBUnyXFQESi4bYlZMZVy5qWkSOE6KCZmopb0JJrzobV16LZgjFV+YAiHSqkaUbkNRUViSuSS5pFYETooJmyyjxW4GSZgMpyXHKlCkuSRsAgMRCjhMAAEBA5DgBAAAEROAEAAAQEDlOyUizX3SVcRX+S+sXSQQAILVQ1pKKvqoy/rmK1RI4JSMFTbGvdg0AAFKHbdu2nfPi5wROyci/xIQ+GJX+BwAAKU/XIFTHhn+cPhsCp2TkD88paCJwAgAgdQmSRkNyOAAAQEAETgAAAAEROAEAAARE4AQAABAQgRMAAEBABE4AAACREDgtXrzYbr31VlepU1MAZ8yYcUYlzwEDBlihQoUsa9as1rBhQ9u0aVOMZf755x9r06aNm96fK1cu69ixox08eDDGMmvWrLE6depYlixZXJ2GYcOGndGWadOmWZkyZdwyFStWtDlz5iS4LQAAILqlaOB06NAhq1y5sr388stxPq8AZ8yYMTZu3Dj79ttvLXv27Na4cWM7evRoaBkFTevWrbOFCxfa7NmzXTD2wAMPxChq1ahRIytatKitXLnShg8fbk8//bS9/vrroWWWLFlid999twu6Vq1aZc2aNXO3H3/8MUFtAQAAUc5LJdSU6dOnh+6fPn3aK1iwoDd8+PDQY3v37vUyZ87svffee+7++vXr3e999913oWXmzp3rpUuXzvvzzz/d/VdeecXLnTu3d+zYsdAyffr08UqXLh26f+edd3pNmjSJ0Z4aNWp4Dz74YOC2BLFv3z7XXv0PAABSh4Qcn1NtjtOWLVtsx44dbkjMlzNnTqtRo4YtXbrU3df/Gp676qqrQstoeV2gT71C/jJ169a1TJkyhZZRT9HGjRttz549oWXC38dfxn+fIG0BAADRL9VeckWBihQoUCDG47rvP6f/8+fPH+P5jBkzWp48eWIsU7x48TNew38ud+7c7v9zvc+52hKXY8eOuVv4sCEAAIhcqTZwigaDBw+2QYMGJct7Fev7SbK8T6T7bUiTRHst1vm5sb4jd52zvpN/G0dkSLVDdQULFnT/79y5M8bjuu8/p/937doV4/mTJ0+6mXbhy8T1GuHvEd8y4c+fqy1x6devn+3bty9027ZtW4LWAQAASF1SbeCk4TUFJYsWLYox1KXcpZo1a7r7+n/v3r1utpzvs88+s9OnT7v8I38ZzbQ7ceJEaBnNwCtdurQbpvOXCX8ffxn/fYK0JS6ZM2d2ZRLCbwAAIHKlaOCkekurV692Nz8JWz9v3brV1XXq0aOHPffcczZz5kxbu3attW3b1tV8UqkAKVu2rN14443WqVMnW758uX3zzTfWtWtXa9WqlVtOWrdu7RLDVWpAZQumTp1qo0ePtl69eoXa0b17d5s3b56NGDHCNmzY4MoVrFixwr2WBGkLAACIfima46TgpH79+qH7fjDTrl07mzhxovXu3dvVelJdJvUs1a5d2wU4KlLpe/fdd12A06BBAzebrkWLFq7eUvjstwULFliXLl2sWrVqljdvXlfIMrzW07XXXmuTJ0+2/v372xNPPGGlSpVyxTgrVKgQWiZIWwAAQHRLp5oEKd2ItELDewrklO+U2MN2JHIGQ7Jy8mJ9Jz+Sw5MXyeFp7/icanOcAAAAUhsCJwAAgIAInAAAAAIicAIAAAiIwAkAACAgAicAAICACJwAAAACInACAAAIiMAJAAAgIAInAACAgAicAAAAAiJwAgAACIjACQAAICACJwAAgIAInAAAAAIicAIAAAiIwAkAACAgAicAAICACJwAAAACInACAAAIiMAJAAAgIAInAACAgAicAAAAAiJwAgAACIjACQAAICACJwAAgIAInAAAAAIicAIAAAiIwAkAACAgAicAAICACJwAAAACInACAAAIiMAJAAAgIAInAACAgAicAAAAAiJwAgAACIjACQAAICACJwAAgIAInAAAAAIicAIAAAiIwAkAACAgAicAAICACJwAAAACInACAACIhsDp1KlT9tRTT1nx4sUta9asVqJECXv22WfN87zQMvp5wIABVqhQIbdMw4YNbdOmTTFe559//rE2bdpYjhw5LFeuXNaxY0c7ePBgjGXWrFljderUsSxZsljhwoVt2LBhZ7Rn2rRpVqZMGbdMxYoVbc6cOUn41wMAgNQmVQdOQ4cOtVdffdXGjh1rP/30k7uvgOall14KLaP7Y8aMsXHjxtm3335r2bNnt8aNG9vRo0dDyyhoWrdunS1cuNBmz55tixcvtgceeCD0/P79+61Ro0ZWtGhRW7lypQ0fPtyefvppe/3110PLLFmyxO6++24XdK1atcqaNWvmbj/++GMyrhEAAJCSUnXgpGCladOm1qRJEytWrJi1bNnSBTjLly8P9TaNGjXK+vfv75arVKmSvf3227Z9+3abMWOGW0YB17x58+zNN9+0GjVqWO3atV3gNWXKFLecvPvuu3b8+HEbP368lS9f3lq1amXdunWzkSNHhtoyevRou/HGG+3xxx+3smXLup6vqlWruqAOAACkDak6cLr22mtt0aJF9vPPP7v7P/zwg3399dd20003uftbtmyxHTt2uOE5X86cOV2AtHTpUndf/2t47qqrrgoto+XTp0/veqj8ZerWrWuZMmUKLaNeq40bN9qePXtCy4S/j7+M/z5xOXbsmOvNCr8BAIDIldFSsb59+7pgQ3lFGTJkcDlPzz//vBt6EwVNUqBAgRi/p/v+c/o/f/78MZ7PmDGj5cmTJ8YyyqOK/Rr+c7lz53b/n+194jJ48GAbNGjQv1gDAAAgNUnVPU7vv/++G0abPHmyff/99zZp0iR74YUX3P+RoF+/frZv377Qbdu2bSndJAAAEK09TsonUq+Tco5EM9l+//1315PTrl07K1iwoHt8586dbladT/erVKniftYyu3btivG6J0+edDPt/N/X//qdcP79cy3jPx+XzJkzuxsAAIgOqbrH6fDhwy4XKZyG7E6fPu1+1vCaAhflQfk0tKfcpZo1a7r7+n/v3r1utpzvs88+c6+hXCh/Gc20O3HiRGgZzcArXbq0G6bzlwl/H38Z/30AAED0S9WB06233upymj755BP77bffbPr06W6m2+233+6eT5cunfXo0cOee+45mzlzpq1du9batm1rl1xyiSsVIJoBp9lwnTp1crPxvvnmG+vatavrxdJy0rp1a5cYrlIDKlswdepUN4uuV69eobZ0797dzc4bMWKEbdiwwZUrWLFihXstAACQNqTqoTqVDVABzM6dO7vhNgU6Dz74oCt46evdu7cdOnTI1WVSz5LKDSjAUZFKn/KkFOA0aNDA9WC1aNHC1X4Kn4m3YMEC69Kli1WrVs3y5s3r3iO81pNm+CnXSqUPnnjiCStVqpQreVChQoVkXCMAACAlpfPCy3AjSWkYUUGaEsVVxTwxFev7SaK+XrT6bUiTRHst1vm5sb4jd52zvpN/G0dkHJ9T9VAdAABAakLgBAAAEBCBEwAAQEAETgAAAAEROAEAAARE4AQAABAQgRMAAEBABE4AAAABETgBAAAEROAEAACQXIHTqVOnbPXq1bZnz55/+1IAAADRFTj16NHD3nrrrVDQdN1111nVqlWtcOHC9sUXXyRFGwEAACIzcPrggw+scuXK7udZs2bZli1bbMOGDdazZ0978sknk6KNAAAAkRk4/fXXX1awYEH385w5c+yOO+6wK664wjp06GBr165NijYCAABEZuBUoEABW79+vRummzdvnt1www3u8cOHD1uGDBmSoo0AAACpQsaE/kL79u3tzjvvtEKFClm6dOmsYcOG7vFvv/3WypQpkxRtBAAAiMzA6emnn7YKFSrYtm3b3DBd5syZ3ePqberbt29StBEAACAyA6ejR49ay5Ytz3i8Xbt2idUmAACA6AiccuXKZdWrV3dlCOrVq2fXXnutZc2aNWlaBwAAEMnJ4Z9++qndeOONLqepadOmljt3bqtdu7YrRbBw4cKkaSUAAEAkBk4Kkp544glbsGCB7d271z7//HMrWbKkDRs2zAVUAAAA0SrBQ3Xy888/uyrh/u3YsWN2yy23uKE7AACAaJXgwOnSSy+1I0eOuCBJtz59+lilSpVcaQIAAIBoluChunz58rlilzt27HC3nTt3ukAKAAAg2iU4cFq9erULmFSzSUN0ynfKmzevm13HteoAAEA0O68cJ5UkuO2226xWrVouYPr444/tvffeczPtnn/++cRvJQAAQCQGTh999FEoKVzXrMuTJ4+baTdixAhX2wkAACBaJThweuihh6xu3br2wAMPuECpYsWKSdMyAACASA+cdu3alTQtAQAAiMYcp1OnTtmMGTPsp59+cvfLlSvnqojrQr8AAADRKsGB0y+//GI333yz/fnnn1a6dGn32ODBg61w4cL2ySefWIkSJZKinQAAAJFXjqBbt24uONq2bZt9//337rZ161YrXry4ew4AACBaJbjH6csvv7Rly5a52XS+iy++2IYMGeLKEwAAAESrBPc4Zc6c2Q4cOHDG4wcPHrRMmTIlVrsAAAAiP3DSxXxVikDFLj3Pczf1QKlMgYpiAgAARKsEB05jxoxxOU41a9a0LFmyuJuG6EqWLGmjR49OmlYCAABEYo6TLreiS6xs2rTJNmzY4B4rW7asC5wAAACi2XnVcZJSpUq5GwAAQFoRKHDq1atX4BccOXLkv2kPAABAZAdOq1atCvRi6dKl+7ftAQAAiOzA6fPPP0/6lgAAAETLrLrNmze70gMAAABpVeDASYngu3fvDt2/6667bOfOnUnVLgAAgMgNnGL3Ns2ZM8cOHTpkSU0XE77nnnvcZV2yZs1qFStWtBUrVsRo14ABA6xQoULu+YYNG7pSCeH++ecfa9OmjeXIkcOVU+jYsaOrdB5uzZo1VqdOHVeXShcsHjZs2BltmTZtmpUpU8Yto3ZoHQAAgLQjwQUwk9OePXtccc0LLrjA5s6da+vXr7cRI0ZY7ty5Q8sowFFRznHjxrlq5tmzZ7fGjRvb0aNHQ8soaFq3bp0tXLjQZs+ebYsXL3bVz3379++3Ro0aWdGiRW3lypU2fPhwe/rpp+31118PLbNkyRK7++67XdClZPlmzZq5248//piMawQAAEREHSfNmIs9ay6pZ9ENHTrU9f5MmDAh9Fjx4sVj9DaNGjXK+vfvb02bNnWPvf3221agQAGbMWOGtWrVyn766SebN2+efffdd3bVVVe5ZV566SW7+eab7YUXXrBLLrnE3n33XTt+/LiNHz/eXW+vfPnytnr1aldawQ+wVBX9xhtvtMcff9zdf/bZZ10gNnbsWBe0AQCA6Jegobr77rvPmjdv7m7q0dH16fz7/i0xzZw50wU7d9xxh+XPn9+uvPJKe+ONN0LPb9myxXbs2OGG53w5c+a0GjVq2NKlS919/a/hOT9oEi2fPn1610PlL1O3bt0YFylWr9XGjRtdr5e/TPj7+Mv47xOXY8eOud6s8BsAAEgDgVO7du1c8KLARDflHam3xr/v3xKTZvK9+uqrLjF9/vz59vDDD1u3bt1s0qRJ7nkFTaIepnC67z+n/9XucBkzZrQ8efLEWCau1wh/j/iW8Z+Py+DBg2OsG/WeAQCANDBUFz5cllxOnz7teor+85//uPvqcVJOkYbGFMildv369YtRdV09TgRPAABErlSdHK6ZcuXKlYvxmC4ovHXrVvdzwYIF3f+xyyLovv+c/t+1a1eM50+ePOlm2oUvE9drhL9HfMv4z8clc+bMbiZf+A0AAESuVB04aUad8ozC/fzzz272m58orsBl0aJFMXp1lLtUs2ZNd1//7927182W83322WeuN0u5UP4ymml34sSJ0DJK/C5dunRoBp+WCX8ffxn/fQAAQPRL1YFTz549bdmyZW6o7pdffrHJkye7EgFdunQJzerr0aOHPffccy6RfO3atda2bVuXe6VSAX4PlWbDderUyZYvX27ffPONde3a1c2403LSunVrlxiuUgMqWzB16lQ3iy58mK179+5udp7KIWzYsMGVK1A9Kb0WAABIGwLnOKWEq6++2qZPn+5yhZ555hnXw6TyA6rL5Ovdu7crxKmyAepZql27tgtwVKTSp3IDCnAaNGjgZtO1aNHC1X7yKXF7wYIFLiCrVq2a5c2b1xXVDK/1dO2117rATaUPnnjiCZewrpIHFSpUSMY1AgAAUlI6L8AF6KpWreqGqTRspQDmscces2zZsiVPC6OIhhEVpO3bty/R852K9f0kUV8vWv02pEmivRbr/NxY35G7zlnfyb+NIzKOz4GG6lRE0r+8yqBBg864XAkAAEBaEGiorkqVKta+fXs3DKYOKlXcvvDCC+NcVkNcAAAAaTZwmjhxog0cONBd500J2bpunIpIxqbnCJwAAECaDpw0LX/KlCnuZyVXK98pdjVuAACAaJfgWXWqfwQAAJAWnVc5gl9//dWVBVDSuKi6t+oclShRIrHbBwAAELkFMHWxXQVKKiZZqVIld1Ol7vLly7tK2gAAANEqwT1Offv2dRW9hwwZcsbjffr0sRtuuCEx2wcAABC5PU4antOlSWLr0KGDrV+/PrHaBQAAEPmBU758+Wz16tVnPK7HmGkHAACiWYKH6nSxXF3DbfPmze76baIL5w4dOjTGRXEBAAAsrQdOTz31lF100UU2YsQId/FdueSSS+zpp5+2bt26JUUbAQAAIjNwUnVwJYfrduDAAfeYAikAAIBod151nHwETAAAIC1JcHI4AABAWkXgBAAAEBCBEwAAQFIETidOnLAGDRrYpk2bEvJrAAAAaS9wuuCCC2zNmjVJ1xoAAIBoGqq755577K233kqa1gAAAERTOYKTJ0/a+PHj7dNPP7Vq1apZ9uzZYzw/cuTIxGwfAABA5AZOP/74o1WtWtX9/PPPP59RHBMAACBaJThw+vzzz5OmJQAAANFajuCXX36x+fPn25EjR9x9z/MSs10AAACRHzj9/fffriTBFVdcYTfffLP973//c4937NjRHn300aRoIwAAQGQGTrq4r8oSbN261bJlyxZ6/K677rJ58+YldvsAAAAiN8dpwYIFbojusssui/F4qVKl7Pfff0/MtgEAAER2j9OhQ4di9DT5/vnnH8ucOXNitQsAACDyA6c6derY22+/HaMEwenTp23YsGFWv379xG4fAABA5A7VKUBScviKFSvs+PHj1rt3b1u3bp3rcfrmm2+SppUAAACR2ONUoUIFV/iydu3a1rRpUzd017x5c1u1apWVKFEiaVoJAAAQiT1OkjNnTnvyyScTvzUAAADRFjjt2bPHXej3p59+cvfLlStn7du3tzx58iR2+wAAACJ3qG7x4sVWrFgxGzNmjAugdNPPxYsXd88BAABEqwT3OHXp0sUVu3z11VctQ4YM7rFTp05Z586d3XNr165NinYCAABEXo+TrlGnS6v4QZPo5169ernnAAAAolWCA6eqVauGcpvC6bHKlSsnVrsAAAAic6huzZo1oZ+7detm3bt3d71L11xzjXts2bJl9vLLL9uQIUOSrqUAAACREDhVqVLFVQj3PC/0mApfxta6dWuX/wQAAJBmA6ctW7YkfUsAAACiIXAqWrRo0rcEAAAgGgtgbt++3b7++mvbtWuXu8BvOOVAAQAARKMEB04TJ060Bx980DJlymQXX3yxy33y6WcCJwAAEK0SXI7gqaeesgEDBti+ffvst99+c/lP/m3z5s2WlDRrT8FZjx49Qo8dPXrUFd5UEHfhhRdaixYtbOfOnTF+b+vWrdakSRPLli2b5c+f3x5//HE7efJkjGW++OILV2ohc+bMVrJkSRcgxqaZg6qaniVLFqtRo4YtX748Cf9aAAAQ8YHT4cOHrVWrVpY+fYJ/9V/57rvv7LXXXrNKlSrFeLxnz542a9YsmzZtmn355ZduGLF58+ah51XVXEHT8ePHbcmSJTZp0iQXFCn48yno0zL169e31atXu8Ds/vvvt/nz54eWmTp1qivyOXDgQPv+++9dzarGjRu74UoAAJA2JDj66dixowtSktPBgwetTZs29sYbb1ju3LlDj6vXSxcbHjlypF1//fVWrVo1mzBhgguQVFtKFixYYOvXr7f//ve/rqzCTTfdZM8++6zrPVIwJePGjXPX2hsxYoSVLVvWunbtai1btrQXX3wx9F56j06dOrmLGeuixvod9WCNHz8+WdcFAACIoMBp8ODBrmenXr169sgjj7hemPBbUtBQnHqEGjZsGOPxlStX2okTJ2I8XqZMGStSpIgtXbrU3df/FStWtAIFCoSWUU/R/v37bd26daFlYr+2lvFfQwGW3it8GfW46b6/DAAAiH4Zzydw0hBW6dKl3f3YyeGJbcqUKW5oTEN1se3YscMlqefKlSvG4wqS9Jy/THjQ5D/vP3e2ZRRcHTlyxPbs2eOG/OJaZsOGDfG2/dixY+7m0+sBAIA0FDhpOEvDU/fdd58ltW3btrnLuyxcuNAlZEcaBZmDBg1K6WYAAICUGqrTrLNatWpZctDwmJKvNdstY8aM7qZhwjFjxrif1eOjYbS9e/fG+D3NqitYsKD7Wf/HnmXn3z/XMjly5LCsWbNa3rx5LUOGDHEu479GXPr16+fysPybAkEAAJCGAif1AL300kuWHBo0aGBr1651M93821VXXeUSxf2fL7jgAlu0aFHodzZu3OjKD9SsWdPd1/96jfDZb+rBUlCkJG9/mfDX8JfxX0PDgUo8D19GhT91318mviBT7xN+AwAAaWioTrWLPvvsM5s9e7aVL1/eBS7hPvroo0Rr3EUXXWQVKlSI8Vj27NldzSb/cc3yU1J6njx5XGCihHUFM9dcc417vlGjRi5Auvfee23YsGEun6l///4u4VyBjTz00EM2duxYd+HiDh06uL/v/ffft08++ST0vnqPdu3auWCtevXqNmrUKDt06JCbZQcAANKGBAdOSsQOr5OU0lQyQDPcVPhSidiaDffKK6+EntcQm4K8hx9+2AVUCrwUAD3zzDOhZVSKQEGSakKNHj3aLrvsMnvzzTfda/nuuusu2717t6v/pOBLpQ3mzZt3RsI4AACIXuk8z/NSuhFphWbV5cyZ0+U7JfawXbG+/693DPH7bUiTRHst1vm5sb4jd52zvpN/G0dkHJ+Tt/w3AABAWhqq07DW2eo1JfX16gAAACImcAq/wK6ocveqVatcvo8ungsAABCtMp5POYK46NpvK1asSIw2AQAApEqJluOki+d++OGHifVyAAAA0Rs4ffDBB66WEgAAQLRK8FDdlVdeGSM5XNUMVNdINY7C6ycBAABEmwQHTs2aNYtxX8Un8+XLZ/Xq1bMyZcokZtsAAAAiO3AaOHBg0rQEAAAglaMAJgAAQGL3OGlI7myFL0XPnzx5MuhLAgAARGfgNH369HifW7p0qY0ZM8ZOnz6dWO0CAACI3MCpadOmZzy2ceNG69u3r82aNcvatGljzzzzTGK3DwAAILJznLZv326dOnWyihUruqG51atX26RJk6xo0aKJ30IAAIBIDJz27dtnffr0sZIlS9q6dets0aJFrrepQoUKSddCAACASBuqGzZsmA0dOtQKFixo7733XpxDdwAAANEscOCkXKasWbO63iYNy+kWl48++igx2wcAABB5gVPbtm3PWY4AAAAgmgUOnCZOnJi0LQEAAEjlqBwOAAAQEIETAABAQAROAAAAARE4AQAABETgBAAAEBCBEwAAQEAETgAAAAEROAEAAARE4AQAABAQgRMAAEBABE4AAAABETgBAAAEROAEAAAQEIETAABAQAROAAAAARE4AQAABETgBAAAEBCBEwAAQEAETgAAAAEROAEAAARE4AQAABAQgRMAAEBABE4AAAABETgBAABEQ+A0ePBgu/rqq+2iiy6y/PnzW7NmzWzjxo0xljl69Kh16dLFLr74YrvwwgutRYsWtnPnzhjLbN261Zo0aWLZsmVzr/P444/byZMnYyzzxRdfWNWqVS1z5sxWsmRJmzhx4hntefnll61YsWKWJUsWq1Gjhi1fvjyJ/nIAAJAaperA6csvv3RB0bJly2zhwoV24sQJa9SokR06dCi0TM+ePW3WrFk2bdo0t/z27dutefPmoedPnTrlgqbjx4/bkiVLbNKkSS4oGjBgQGiZLVu2uGXq169vq1evth49etj9999v8+fPDy0zdepU69Wrlw0cONC+//57q1y5sjVu3Nh27dqVjGsEAACkpHSe53kWIXbv3u16jBQg1a1b1/bt22f58uWzyZMnW8uWLd0yGzZssLJly9rSpUvtmmuusblz59ott9ziAqoCBQq4ZcaNG2d9+vRxr5cpUyb38yeffGI//vhj6L1atWple/futXnz5rn76mFS79fYsWPd/dOnT1vhwoXtkUcesb59+wZq//79+y1nzpyu3Tly5EjUdVOs7yeJ+nrR6rchTRLttVjn58b6jtx1zvpO/m0cKSchx+dU3eMUm/4gyZMnj/t/5cqVrheqYcOGoWXKlCljRYoUcYGT6P+KFSuGgiZRT5FW0rp160LLhL+Gv4z/Guqt0nuFL5M+fXp3318GAABEv4wWIdTDoyG0WrVqWYUKFdxjO3bscD1GuXLlirGsgiQ95y8THjT5z/vPnW0ZBVdHjhyxPXv2uCG/uJZRD1d8jh075m4+vR4AAIhcEdPjpFwnDaVNmTLFIoWS29X15980tAcAACJXRAROXbt2tdmzZ9vnn39ul112WejxggULumE05SKF06w6PecvE3uWnX//XMtonDNr1qyWN29ey5AhQ5zL+K8Rl379+rnhRf+2bdu2814HAAAg5aXqwEl56wqapk+fbp999pkVL148xvPVqlWzCy64wBYtWhR6TOUKVH6gZs2a7r7+X7t2bYzZb5qhp6CoXLlyoWXCX8Nfxn8NDQfqvcKX0dCh7vvLxEWlDfQ+4TcAABC5Mqb24TnNmPv4449dLSc/J0nDXuoJ0v8dO3Z0ZQKUMK7ARLPcFMxoRp2ofIECpHvvvdeGDRvmXqN///7utRXYyEMPPeRmy/Xu3ds6dOjggrT333/fzbTz6T3atWtnV111lVWvXt1GjRrlyiK0b98+hdYOAABIbqk6cHr11Vfd//Xq1Yvx+IQJE+y+++5zP7/44otuhpsKXyoRW7PhXnnlldCyGmLTMN/DDz/sAqrs2bO7AOiZZ54JLaOeLAVJqgk1evRoNxz45ptvutfy3XXXXa58geo/KfiqUqWKK1UQO2EcAABEr1QdOAUpMaUq3qrorVt8ihYtanPmzDnr6yg4W7Vq1VmX0bChbgAAJDZqZ0VG7axUneMEAACQmhA4AQAABETgBAAAEBCBEwAAQEAETgAAAAEROAEAAARE4AQAABAQgRMAAEBABE4AAAABETgBAAAEROAEAAAQEIETAABAQAROAAAAARE4AQAABETgBAAAEBCBEwAAQEAETgAAAAEROAEAAARE4AQAABAQgRMAAEBABE4AAAABETgBAAAEROAEAAAQEIETAABAQAROAAAAARE4AQAABETgBAAAEBCBEwAAQEAETgAAAAEROAEAAARE4AQAABAQgRMAAEBABE4AAAABETgBAAAEROAEAAAQEIETAABAQAROAAAAARE4AQAABETgBAAAEBCBEwAAQEAETgAAAAEROAEAAARE4AQAABAQgVMCvfzyy1asWDHLkiWL1ahRw5YvX57STQIAAMmEwCkBpk6dar169bKBAwfa999/b5UrV7bGjRvbrl27UrppAAAgGRA4JcDIkSOtU6dO1r59eytXrpyNGzfOsmXLZuPHj0/ppgEAgGRA4BTQ8ePHbeXKldawYcPQY+nTp3f3ly5dmqJtAwAAySNjMr1PxPvrr7/s1KlTVqBAgRiP6/6GDRvi/J1jx465m2/fvn3u//379yd6+04fO5zorxmNEnPds87PjfUdueuc9R0M23jyS4pjqP+anuedc1kCpyQ0ePBgGzRo0BmPFy5cOEXaA7Oco1K6BWkL6zv5sc6TF+s7utb5gQMHLGfOnGddhsApoLx581qGDBls586dMR7X/YIFC8b5O/369XPJ5L7Tp0/bP//8YxdffLGlS5fOopmidwWI27Ztsxw5cqR0c9IE1nnyYn0nL9Z38ktL69zzPBc0XXLJJedclsApoEyZMlm1atVs0aJF1qxZs1AgpPtdu3aN83cyZ87sbuFy5cplaYm+bNH+hUttWOfJi/WdvFjfyS+trPOc5+hp8hE4JYB6j9q1a2dXXXWVVa9e3UaNGmWHDh1ys+wAAED0I3BKgLvuust2795tAwYMsB07dliVKlVs3rx5ZySMAwCA6ETglEAalotvaA7/j4YoVSg09lAlkg7rPHmxvpMX6zv5sc7jls4LMvcOAAAAFMAEAAAIisAJAAAgIAInAACAgAicAAAAAiJwAgAACIjACQAQkY4ePZrSTUjTvP+blL9ixQr76aefLK0gcEKqsX37dluyZElKNyNq160uD/S///0vpZsCJIpffvnFnnrqKZswYUKgK9oj8aVLl87mzp1rtWvXtj///NNOnjxpaQGBE1LNmWObNm1cVfavvvoqpZsTVdatW2c333yzjR8/3n7++eeUbg7CztRxftauXWsNGjSwXbt2ueuLRftF01Orf/75x1avXm3PPfecNWzY0DJmTBs1tQmckCpkyZLFnnnmGXc1bl0D8Msvv0zpJkVN0FSrVi1r1KiR9e3b16677rqUblKap6BJB/pvv/3W3nvvPXdDcJs2bXJBU+vWrW3MmDHWvHnzM5YhME1669evt0KFCtkbb7xh+fPnt7SEwAkp7tSpU+7/OnXq2OjRo23Lli1uh0jw9O/s2bPHOnfubA8++KANGzbMKlasGHpOF6feu3dv6D4HmuSjoGnGjBlWr149Gzp0qN17771222232bZt21K6aRGxr3j99detSZMmNnjwYMuRI4d7/O+//3Y9H1OmTHHXE6UHKul4/7evKFeunD388MP222+/2e+//26nT5+2tILACSlGX7g1a9bYvn37Qo/VrFnTBU+bN2+m5+lfUnCkdasudN8333xjQ4YMsSuvvNIdrMeOHese50CTfAecAwcO2GuvveZun332ma1atcod9Nu2beu+E4hfhgwZbOvWrXbs2LHQdjt9+nTr1auXO/HSdUR1grBy5Ur3PCcEicdfl+nC9hXaR+vk7Pnnn7eZM2daWpE2BiSR6iiR8PLLL3c/K7GwVKlSduutt1qNGjXcDvDdd991OU8vv/yySzhU1zwSRmfeOhNUAOWfqSvP6aKLLrLrr7/erdcnn3zSihYt6tY9kpYOOJ9++qm98sorduGFF1rdunUtT5487vb111+770H79u1dsnOxYsVSurmp8sCt7bhgwYJuCFrrUYHm5MmTQzl82ne0a9fO9YQsX76cE4JEHl7WidfXX3/tTsjKly/v9tE6+dLnoqFT9fjphCzq6SK/QHL766+/vOuuu85Lly6d17dvX69OnTpepUqVvBw5cnitW7f2pk6d6r399tvelVde6bVr185btGhRSjc5Ij3wwANuHZcqVcrLlCmTN2zYMG/t2rXuud9//9274oorvBdeeCGlm5lmfPPNN24bz5Ili7dmzRr32KlTp9z/W7du9S6//HKvSpUq7rNBTKdPn3b///bbb16DBg3cvqFYsWLelClTvD///DO03MCBA72aNWt6J06cSMHWRp8PP/zQbbv33nuvd/vtt3tlypTxWrRoEXq+c+fO7vn333/fi3YETkgxu3fv9mrXru1Vr17d++WXX7x//vnHe+ONN7xu3bp5uXPndjtHHfR1u/vuu73Dhw+ndJMjkg4s77zzjrdly5YYj2t916pVy5s4cWKKtS0tWr58uXfxxRd7LVu29Pbv3x8jKNBnVKFCBRccwIuxbsJ/3rdvn7d3717vwIEDZyzfqVMnr23btt6xY8eStZ3RTPtnBfWvvPKKu79hwwa3j+7atWuM5dq0aeNdcsklcX4u0SSd/knpXi+kDUrgVNd6tmzZrGzZsqHHNONL5Qg+/vhjK1mypHt8x44dblkl0SoPasSIEaHfwdm70zU8p/WpZE1/nfnPhevfv79NnTrV1XcqUqRICrU6evnrXMMa6dOnd0OkPtUr0/DSTTfd5IZQ9Zw+Ly2nIdS0Mq07IUNEumn6u3L2NCSXOXPmGMtqRq6S7ZU7ppIm7C8Sj4bnlMukffHvv//u1r+233Hjxrnn9dlo9q6/79ZwalRL6cgNacP69eu9+vXrezfeeKPXvn37GM/9/fff3tVXX+2VLl3a27hx4xm/e+TIkWRsaWTyz8TVna4u9EKFCnklSpTwbr31Vu/gwYMxll2yZInXq1cv1+uxatWqFGpx2vg8Zs+e7YahNfymnlWt76NHj4aG7XLmzOndc889rgcFcfvggw+8Cy+80A3t16hRw/VAP/bYY97mzZtDy6gnpEOHDl6RIkW877//PkXbG41Wrlzp3XDDDd63337rFS5c2KUAnDx50j2nbbpLly7eTz/95KUVBE5Icsrl0EH6ySefjLGz0+O7du2KETyVLVvW+/nnn8/oose5ffHFF17WrFm9V1991fv888+9jz76yCtZsqR3zTXXhIJP5Y4pl0xBrJ/rhKQxc+ZM76KLLvIGDBjgffXVV97111/vlStXzvv4449DwZOCWAUCHTt2ZHuPZ4hIwZCG8P31895773l58+b1+vTp4w7e2ocoaHrkkUfiPPHCuWnd+us3ru1Q++3LLrvMbasPPPBAjOd69Ojh9ifKW00rCJyQpP744w8XDKmHI9yQIUO8Cy64wHvuuee8PXv2hIInJXUWLFjQ7TCRMM8++6xL2gynnBnlJtxxxx2hx5YuXert3LkzBVqYdmi9q3dk5MiR7r7Wd/HixV1PYJ48eVzw5OfsLVu2zOWM4Ew6uVIC+OrVq2Mc0N99910vffr0LiAVrUtyIM+fv+78vDCtV00a0UmY9uGycOFCt89+6KGHvK+//tr1Qmm/rl5Tf6JDWkHghCTvZldP0qZNm0KzhxQ0qetdZy4ZMmTwnn/++VDwpIRxJYUTOAXnH1A0BKqZRj5/VtGkSZNcT4dmbSF5aHvXDEYlf2/fvt3NatQBRzQhQp+HZh/5PU/wvEOHDrnvv3pLdbDW8KX2A9pHqGdOwteXkuiZEfrvafayTlZ37Njh7mu71P5Zw8vabnXi5Q/DTZs2zQ3VKQFcJ8RXXXVVmhzupwAmkpQKWCppU0nfSnw9ceKEq1vz0UcfuSRO1WlSkrIKqSmhOW/evLZgwQIrUaJESjc91dI6PHjwoLsauaqD+0nfd911l0tEVl0b8ROMtb4PHz5MTZsk5M+x0cWURdv7HXfc4ZK+VeG6QoUKNnz4cPfcFVdcYRs2bHCXwNFnCXPXUFTtJSUdK2FeNYJ0X9u5kpI7dOjgLurrJ4QfP37c/exXDsf5Ux234sWL2w033GB//PGHfffdd64204oVK9zlgJRkr8LEGzdutJYtW9rSpUtt/vz5buKO9tVVqlSxtIbACUl6MFGhPwVMOsCrSNoFF1xg999/v/uSii4H0qpVKxdgqSqwaHnETQePHj162LXXXusKJuqyBzow6/Hq1atb1apV7b///a+7iQ7MmvGigDR79uwp3fyonvk1a9Ysu+WWW9zBRo/5RSw1O1QHJn/966K0OihpppK+H2mdZmrp8jOabatgUpXUH3roIXctP+0bLr30UrdtaxaXZoAuXrzYXddSs7sojPvvqRDrCy+84ILQ+vXru6rrlStXdvvjatWquZNa7W9UnFjB06WXXupOBHQCkDt3bkuTUrrLC9FFhfvmzp0bGibSUJ0SCidPnnxGEqKG7jSmriE7FcGkYN3Z/fDDDy5R9r777vNefPFFt271c8aMGV0hum3btrmhjTvvvNPlhaibXUmbqrfCTKOkNWvWLFfUUjlNsfM9WrVq5YY7xo0b5z344IMuJ4Q6Tf9vm86WLZvXr1+/M77/SgLXTETlimm4WUPRmvygoq3ly5dnmz5PfspE7CRwfRY33XST25+sW7cuxrIaer7tttvcvvzXX3/10joCJyQafRH15dKOTcmvx48fd4FRs2bNXFKhDi7h9KV84oknvEsvvTQ0kw5nP8BofcUuzzBq1CiXk6AK66IASlPde/fu7b388sus2ySmPKZ69ep5Tz31VIzH/UBA34FGjRq5g33VqlXTZE5IXJRzp9lx4RMXtA8JD6AUbGpG7uuvv+7u//jjj+7kTLlQOH9ah/Pnzw/lOOlqDaKkbwWqKmXiz3j2AyxNYNBJ2QYmMhA4IXH4Zyaq5qvkbn35NB1bdGaoA4uCJ9Vf0TT51157zZXuz5UrF2eO56CzPT+ZPr4DzODBg93Z4OLFi1OolWlH7J4RzZgrWrSoN3369Bjfhdi0nF8pHP//zENNHNHJlj87zhfeG6Jken+2aHzrFsGphIN6lhTE60RMyfcKUH1KxPcnMPizb/3PQyfDIDkciUD5Ncqp0UVllb+hxO8sWbLYs88+a3PmzLErr7zSVUfu3r27Swi/9957beTIkXbkyBGXf6PnET/lFWhdKZ9g06ZN7jHl1Cj5W9Wm5fHHH3cXSlaejXBBgKSxefNm6927t8sD8SkBXPkhylvyc/SUzyfK05k0aZL7OX/+/DGqh6d1ygHTxbyV6P3cc8+5nK+4aDtX/pOQ//jvKXdJ+2Wtd+VHKmdSuaY+JYKrAvvFF1/sclFVCdyfWKIcVZAcjkSgq5Lfd9997pIpuoSKDiIzZ850O7uBAwfaJ5984mbJaVbRjz/+aN9//72bmfH222+75GacXZMmTWzixIn2zjvv2EsvvRQKnsTfoWlnqEt1+AdsZtAlvrVr17rLfWzZssWWL18eelwHEyXOfvrppzZ79mz3mD/R4YMPPrA333zTzXbEmRTsjxkzxm2vCp50IiW6r5MCzfLKmjVraDIJJwQJ559c6eTr2LFjbgajLl2jiQmVKlWyZcuWue3WX06UDK7gSfuU22+/3T3Hug+T0l1eiA49e/Z0+QoagvMryKoOiy6ToARPDWOQ/J3wmjaffvppqACdcsRUQFEVkjV8F971rrwDDYfOmTPHPUYV6sSlitT58+d31apjX8JG9Bn5lwTp3r279+abb7pkZl0tXvlpODvl4elyTI0bN44xbKf1XblyZZe3h4TzhzZ1yavmzZu72ldK/lY6RefOnd1+QhNIVHhY+5fYQ6H6vfCrPeD/R+CEfyU8GNIBPb7gqVatWq6wmn99I5z9IK2ru+uac5qppct2KHlTB+cFCxa4YnVa1+FJ3zrAKEBVsUUkLm2zKl6pnLzwA4u2bc0wUkKtvge6r9lh+hyUCH7zzTcTNJ1n8KS8x6FDh7rcPlUNR8L5J0+a5amZnLqenAJ6zcZt2rSpy4nUrFztVxRIKXjy81K1P9E+CHEjcEKCqXejf//+7gv5559/xnhOB3RdUkLBkz/zRQcUVaFt2LChd+DAgRRqdWTQgVa9SjpQT5w40VXs1U5Ml+vQRZB19jdv3rxQz5MCJV1qRcEVB+mkoYTYunXrum3ep7Nzv0dJybU6OVi+fHnoeW3zXJz6/IKnW265xfXuaTLJihUrUrpJEU0z43Q1AZV7if342LFjvUyZMrmASoG/LuKrhPBrr73WlTDxq7XjTAROSBAdEHQQ19mKZsSortCjjz7qAiXfoEGD3I5PU4j9Ka2aTUTtmvOvaaOL82rIQr0ZGipS751qNemyB/odDjCJL3y48+GHH3a9SLociGYiaRadyj/oEhS61pyGQBTIMkSaOCdmmmmn0gP4d9Rzp21TF/T2e/vDZ0DrWqEKnjQ8qvuqD6cTMf8SK4gbgRMSRF8+TV3Nly+fG4rQgUPd6xo+UsFFTXNdtGhRaLhi9OjRaeqq2UlZ00aBaPbs2UM1bd566y0XxNLTlPjC17umZCvXTNu7tnNdp+udd95xtXB8999/vxuOZrp24mA9Jo4JEya44X5f7MBePdgaxlM5EwTHrDoEopkYmh2n6cAqJ/Cf//zH5s2b52ZnzJ0718306tOnjxUoUMB69eple/futfXr17vyA/4MI8RPs+F0WQ7NevGnZfslB/zZLJ06dXKXQNBUYtH1u3S5Cs2MQeLZunWrPfroo+7nDz/80M2k07XTpk6dal999ZWbGXrPPfdYkSJFQp+drrOoz4bp8omDae+JQ9dM9LfjuGbbap9z+eWX286dO1OkfZGKbznO6YcffrAyZcq4Gjb64qnMQNu2bd3UeF2I8+mnn3ZTWzt27GgTJkxwpQimTJlijz32mPvC5sqVK6X/hKipaaMDs1/TRrjWWeLT1Gyt/8aNG9vdd9/ttuOCBQu6da0DUfj1ufR5qeSGrqGm7wInCUht+xWVh1HpF13bz+eXHtA1RFXuQUE/EiABvVNIg3R5CP9SH7EdPXrUe/XVV11y7DPPPBN6nLIDiTOzSLO1fMpL0JRsDYUqaVzIp0lc4etTU7WVx6cSD7pkisSeETp+/Hg3K0mJ+lS/R2r14YcfujwmzQqNnTemCQ/KlST/NGHS6Z+EBFpIWwX/VEW2Z8+ergq4T0MWGr5QZVmdcasAZteuXd0Vy5944okUbXM00LBnt27d3BBd//79rXbt2u5xXTlew6PqEbnssstSuplRR+tbPaoLFiyw9957zw2TaohaRRpVYTlfvnyuIKAeX716teshVMFXDVGXLl06pZsPxElDySrCqn20ChHXqlXLChUq5Aq5Ks1CvaVcvSGBEhhoIY1QbQ+dcfsXf/QNGTLEPR4+i0tn5JpVp8eHDx+eAq2NPtS0SRm61p+2Y81ilBEjRrjp2R06dAjNEPWvs7Zjxw5XqBSIBJr9qSKYmrSjiQzqVWX23PmhxwnxUtKxzlZ0nTmdpQwbNsxdNmXy5MnuEgj+GbroZ/U8qVR/2bJlU7rpUdPzpER7Xd5DuQi6TA25CElHvUtK/FYun/KafC+++KLL1bviiitcPp/O3mfMmOEuD8K15xBJtD9XnqR/SRsmM5wfAifEoM3hxIkTlilTJndf1+A6cOCA1atXz95//313u/7662P8ji5kqmvOcRBJmgv86qKymsWomV1IGtu2bbOqVavaoUOHXHCkda5haP97MHbsWHetwD///NPdVyCl7wYQSWKf7HJNy/ND4IQYZ9yaKaeDw9VXX239+vVzj9etW9fNMho5cqS7knY4LaOL+3755ZcuBwSJT4Es07OTlspqKDBSj6q2d/WqSnjwpN4olSpQAFu0aNEUbjGAlELghFDJAQ2/aUguS5Ys7ox60KBBoeBJCco7duxw5Qa0jLp4BwwY4A40ixcvdoEWECniOtvWcKgCJg3TdenSxV544QX3OIErgHAZY9xDmqQiiv7sueeff96NfefNm9d27dpl+/fvd3VA1ONUv359V7/po48+sunTp7ucJ+V5kHeDSAyalDOm2XF//PGH3XnnnW5m3IMPPuiW0UmBltGJgYIm5YZQowmA0OOUxvm5HQqKlL/ka9WqlcuvUUXkSy+91Lp372633nqrXXfdda56sooBfvHFF+53gUjzwQcfuMrrlStXdicIu3fvdgUsO3fubPnz53cTIlSCo3nz5vbKK6+kdHMBpCKk1Kdx4Zf6UO+RDBkyxGbNmmUtWrRwwxbbt293dYWU36FcJh1MNDxH0IRIzeVTrt7o0aNdDRudIDz55JOuPpYuESStW7e2xx9/3ObPn+8CK84vAfjocUKo4KKSYHW2rUumKFG2UaNG7nkFTCrdP2bMGFdEDYgkmuygoWYNQVesWNHN/lTPqUoKqMfJz3XSsJwKXWqWqIpe7tu3z/1O+CVWAIAeJ7iDhM6+jxw54qohayq2gia/NIFyO1TTSdfrEmJtRFL+nmbJqaq9Lk59xx132NChQ13ekk4UFDQdPnzYLaseJg1Bq7dVcubMSdAE4AwETnBU3O/VV1+1OnXquOEL5THpoKIDjIYvlCTu162h9gciadJDy5YtbeHCha5sRpEiRWzFihXuJEHDceJfNFnbuCZF6HIUABAfhuoQ73XSNGyhA46u/r5kyRKuZ4SIn/Qwbtw4d205ldXQ9q06TUoEV66frgOo5zVUp7w/AIgL5QhwxrCdcpl0qY8bb7wxdKkPgiZE6qQH5Tf5F0rWRU6zZs3qnnvjjTfc5IfbbrvNDdFlzpzZBU8ETQDOhh4nxIlLfSBaek+V4D1q1CgrXLiwXX755dauXTuXCO5btWqVZc+e3XLlyuUmRwDA2RA4IV5UTEY0BE+qQaYEcOU8KWjSRXuF7RvA+SA5HPHioIJomTGqmaGqgH/77beHnsuYkUwFAAlHjxOAqPfLL7/YI4884iY9PPXUU+56iwBwPuhxAhD1SpYs6SY9qBdVCeHLli1L6SYBiFAETgDSzLCdksIvu+wyu+SSS1K6OQAiFEN1ANIU1W5S1XAAOB8ETgAAAAExVAcAABAQgRMAAEBABE4AAAABETgBAAAEROAEAAAQEIETAABAQAROAAAAARE4AQAABETgBAAAEBCBEwAAgAXz/wHcKJiz1+g4wAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dist_after = df_downsampled['Label_grp'].value_counts()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(dist_after.index, dist_after.values)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Merged Class Distribution (post-undersample)')\n",
    "plt.ylabel('Number of Flows')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00916d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess features & labels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# 1) fill / replace\n",
    "df_downsampled.fillna(0, inplace=True)\n",
    "df_downsampled.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# 2) feature / label split\n",
    "#feature_cols = df_downsampled.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# drop any numeric-derived Label columns\n",
    "#feature_cols = [c for c in feature_cols if 'label' not in c.lower()]\n",
    "#X = df_downsampled[feature_cols].values\n",
    "\n",
    "#le = LabelEncoder()\n",
    "#y = le.fit_transform(df_downsampled['Label_grp'].values)\n",
    "\n",
    "# 3) scale\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d8b169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>188</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60145</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>140894</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>157</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>21072988</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1919</td>\n",
       "      <td>5389</td>\n",
       "      <td>777</td>\n",
       "      <td>0</td>\n",
       "      <td>127.933333</td>\n",
       "      <td>271.190620</td>\n",
       "      <td>...</td>\n",
       "      <td>182895.0</td>\n",
       "      <td>124331.99955</td>\n",
       "      <td>270811</td>\n",
       "      <td>94979</td>\n",
       "      <td>10018510.0</td>\n",
       "      <td>71436.169676</td>\n",
       "      <td>10069023</td>\n",
       "      <td>9967997</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418023</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418024</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418025</th>\n",
       "      <td>80</td>\n",
       "      <td>99307967</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>361</td>\n",
       "      <td>11595</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>45.125000</td>\n",
       "      <td>127.632774</td>\n",
       "      <td>...</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>99300000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99300000</td>\n",
       "      <td>99300000</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418026</th>\n",
       "      <td>80</td>\n",
       "      <td>990</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418027</th>\n",
       "      <td>80</td>\n",
       "      <td>126405</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>378</td>\n",
       "      <td>11595</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>218.238402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418028 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Destination Port  Flow Duration  Total Fwd Packets  \\\n",
       "0                    443              3                  2   \n",
       "1                     53            193                  2   \n",
       "2                  60145             31                  1   \n",
       "3                     53         140894                  1   \n",
       "4                    443       21072988                 15   \n",
       "...                  ...            ...                ...   \n",
       "418023                80              3                  2   \n",
       "418024                80              4                  2   \n",
       "418025                80       99307967                  8   \n",
       "418026                80            990                  2   \n",
       "418027                80         126405                  3   \n",
       "\n",
       "        Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                            0                           12   \n",
       "1                            2                           60   \n",
       "2                            1                            0   \n",
       "3                            1                           64   \n",
       "4                           12                         1919   \n",
       "...                        ...                          ...   \n",
       "418023                       0                            0   \n",
       "418024                       0                            0   \n",
       "418025                       6                          361   \n",
       "418026                       0                            0   \n",
       "418027                       5                          378   \n",
       "\n",
       "        Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
       "0                                 0                      6   \n",
       "1                               188                     30   \n",
       "2                                 0                      0   \n",
       "3                               157                     64   \n",
       "4                              5389                    777   \n",
       "...                             ...                    ...   \n",
       "418023                            0                      0   \n",
       "418024                            0                      0   \n",
       "418025                        11595                    361   \n",
       "418026                            0                      0   \n",
       "418027                        11595                    378   \n",
       "\n",
       "        Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
       "0                           6                6.000000               0.000000   \n",
       "1                          30               30.000000               0.000000   \n",
       "2                           0                0.000000               0.000000   \n",
       "3                          64               64.000000               0.000000   \n",
       "4                           0              127.933333             271.190620   \n",
       "...                       ...                     ...                    ...   \n",
       "418023                      0                0.000000               0.000000   \n",
       "418024                      0                0.000000               0.000000   \n",
       "418025                      0               45.125000             127.632774   \n",
       "418026                      0                0.000000               0.000000   \n",
       "418027                      0              126.000000             218.238402   \n",
       "\n",
       "        ...  Active Mean    Active Std  Active Max  Active Min   Idle Mean  \\\n",
       "0       ...          0.0       0.00000           0           0         0.0   \n",
       "1       ...          0.0       0.00000           0           0         0.0   \n",
       "2       ...          0.0       0.00000           0           0         0.0   \n",
       "3       ...          0.0       0.00000           0           0         0.0   \n",
       "4       ...     182895.0  124331.99955      270811       94979  10018510.0   \n",
       "...     ...          ...           ...         ...         ...         ...   \n",
       "418023  ...          0.0       0.00000           0           0         0.0   \n",
       "418024  ...          0.0       0.00000           0           0         0.0   \n",
       "418025  ...        995.0       0.00000         995         995  99300000.0   \n",
       "418026  ...          0.0       0.00000           0           0         0.0   \n",
       "418027  ...          0.0       0.00000           0           0         0.0   \n",
       "\n",
       "            Idle Std  Idle Max  Idle Min     Label  Label_grp  \n",
       "0           0.000000         0         0    BENIGN     BENIGN  \n",
       "1           0.000000         0         0    BENIGN     BENIGN  \n",
       "2           0.000000         0         0    BENIGN     BENIGN  \n",
       "3           0.000000         0         0    BENIGN     BENIGN  \n",
       "4       71436.169676  10069023   9967997    BENIGN     BENIGN  \n",
       "...              ...       ...       ...       ...        ...  \n",
       "418023      0.000000         0         0  DoS Hulk        DoS  \n",
       "418024      0.000000         0         0  DoS Hulk        DoS  \n",
       "418025      0.000000  99300000  99300000  DoS Hulk        DoS  \n",
       "418026      0.000000         0         0  DoS Hulk        DoS  \n",
       "418027      0.000000         0         0  DoS Hulk        DoS  \n",
       "\n",
       "[418028 rows x 80 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53e20e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chia tập dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_downsampled, test_size=0.2, random_state=42, stratify= df_downsampled['Label_grp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "883b309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8              Numeric features   \n",
      "9          Categorical features   \n",
      "10                   Preprocess   \n",
      "11              Imputation type   \n",
      "12           Numeric imputation   \n",
      "13       Categorical imputation   \n",
      "14     Maximum one-hot encoding   \n",
      "15              Encoding method   \n",
      "16                    Normalize   \n",
      "17             Normalize method   \n",
      "18               Fold Generator   \n",
      "19                  Fold Number   \n",
      "20                     CPU Jobs   \n",
      "21                      Use GPU   \n",
      "22               Log Experiment   \n",
      "23              Experiment Name   \n",
      "24                          USI   \n",
      "\n",
      "                                                Value  \n",
      "0                                                  42  \n",
      "1                                           Label_grp  \n",
      "2                                          Multiclass  \n",
      "3   BENIGN: 0, DDoS: 1, DoS: 2, Other: 3, PortScan: 4  \n",
      "4                                        (334422, 80)  \n",
      "5                                        (334422, 94)  \n",
      "6                                        (234095, 94)  \n",
      "7                                        (100327, 94)  \n",
      "8                                                  78  \n",
      "9                                                   1  \n",
      "10                                               True  \n",
      "11                                             simple  \n",
      "12                                               mean  \n",
      "13                                               mode  \n",
      "14                                                 25  \n",
      "15                                               None  \n",
      "16                                               True  \n",
      "17                                             zscore  \n",
      "18                                    StratifiedKFold  \n",
      "19                                                 10  \n",
      "20                                                 -1  \n",
      "21                                              False  \n",
      "22                                              False  \n",
      "23                                   clf-default-name  \n",
      "24                                               628a  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Turbo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>sklearn.linear_model._logistic.LogisticRegression</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>sklearn.neighbors._classification.KNeighborsCl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>sklearn.naive_bayes.GaussianNB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>sklearn.linear_model._stochastic_gradient.SGDC...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbfsvm</th>\n",
       "      <td>SVM - Radial Kernel</td>\n",
       "      <td>sklearn.svm._classes.SVC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpc</th>\n",
       "      <td>Gaussian Process Classifier</td>\n",
       "      <td>sklearn.gaussian_process._gpc.GaussianProcessC...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>sklearn.neural_network._multilayer_perceptron....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>sklearn.linear_model._ridge.RidgeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.QuadraticDiscrim...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>sklearn.ensemble._weight_boosting.AdaBoostClas...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>sklearn.ensemble._gb.GradientBoostingClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>xgboost.sklearn.XGBClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>lightgbm.sklearn.LGBMClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>sklearn.dummy.DummyClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name  \\\n",
       "ID                                          \n",
       "lr                    Logistic Regression   \n",
       "knn                K Neighbors Classifier   \n",
       "nb                            Naive Bayes   \n",
       "dt               Decision Tree Classifier   \n",
       "svm                   SVM - Linear Kernel   \n",
       "rbfsvm                SVM - Radial Kernel   \n",
       "gpc           Gaussian Process Classifier   \n",
       "mlp                        MLP Classifier   \n",
       "ridge                    Ridge Classifier   \n",
       "rf               Random Forest Classifier   \n",
       "qda       Quadratic Discriminant Analysis   \n",
       "ada                  Ada Boost Classifier   \n",
       "gbc          Gradient Boosting Classifier   \n",
       "lda          Linear Discriminant Analysis   \n",
       "et                 Extra Trees Classifier   \n",
       "xgboost         Extreme Gradient Boosting   \n",
       "lightgbm  Light Gradient Boosting Machine   \n",
       "dummy                    Dummy Classifier   \n",
       "\n",
       "                                                  Reference  Turbo  \n",
       "ID                                                                  \n",
       "lr        sklearn.linear_model._logistic.LogisticRegression   True  \n",
       "knn       sklearn.neighbors._classification.KNeighborsCl...   True  \n",
       "nb                           sklearn.naive_bayes.GaussianNB   True  \n",
       "dt             sklearn.tree._classes.DecisionTreeClassifier   True  \n",
       "svm       sklearn.linear_model._stochastic_gradient.SGDC...   True  \n",
       "rbfsvm                             sklearn.svm._classes.SVC  False  \n",
       "gpc       sklearn.gaussian_process._gpc.GaussianProcessC...  False  \n",
       "mlp       sklearn.neural_network._multilayer_perceptron....  False  \n",
       "ridge           sklearn.linear_model._ridge.RidgeClassifier   True  \n",
       "rf          sklearn.ensemble._forest.RandomForestClassifier   True  \n",
       "qda       sklearn.discriminant_analysis.QuadraticDiscrim...   True  \n",
       "ada       sklearn.ensemble._weight_boosting.AdaBoostClas...   True  \n",
       "gbc         sklearn.ensemble._gb.GradientBoostingClassifier   True  \n",
       "lda       sklearn.discriminant_analysis.LinearDiscrimina...   True  \n",
       "et            sklearn.ensemble._forest.ExtraTreesClassifier   True  \n",
       "xgboost                       xgboost.sklearn.XGBClassifier   True  \n",
       "lightgbm                    lightgbm.sklearn.LGBMClassifier   True  \n",
       "dummy                         sklearn.dummy.DummyClassifier   True  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "# Initialize the setup\n",
    "\n",
    "clf = setup(data=pd.DataFrame(df_train), \n",
    "            target='Label_grp', \n",
    "            session_id=42, \n",
    "            normalize=True, \n",
    "            normalize_method='zscore',  \n",
    "            html=False)\n",
    "models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42aa8dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy  AUC  Recall   Prec.  \\\n",
      "gbc          Gradient Boosting Classifier    0.8000  0.0  0.8000  0.8000   \n",
      "nb                            Naive Bayes    0.7000  0.7  0.7000  0.7000   \n",
      "dt               Decision Tree Classifier    0.7000  0.7  0.7000  0.7000   \n",
      "ridge                    Ridge Classifier    0.7000  0.0  0.7000  0.7000   \n",
      "knn                K Neighbors Classifier    0.6999  0.7  0.6999  0.6999   \n",
      "svm                   SVM - Linear Kernel    0.6999  0.0  0.6999  0.6999   \n",
      "ada                  Ada Boost Classifier    0.6698  0.0  0.6698  0.6442   \n",
      "rf               Random Forest Classifier    0.6000  0.6  0.6000  0.6000   \n",
      "et                 Extra Trees Classifier    0.6000  0.6  0.6000  0.6000   \n",
      "xgboost         Extreme Gradient Boosting    0.6000  0.6  0.6000  0.6000   \n",
      "lightgbm  Light Gradient Boosting Machine    0.6000  0.6  0.6000  0.6000   \n",
      "lda          Linear Discriminant Analysis    0.5349  0.0  0.5349  0.5130   \n",
      "qda       Quadratic Discriminant Analysis    0.5000  0.0  0.5000  0.5000   \n",
      "lr                    Logistic Regression    0.2000  0.0  0.2000  0.2000   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "gbc       0.8000  0.8000  0.8000    67.786  \n",
      "nb        0.7000  0.7000  0.7000     1.579  \n",
      "dt        0.7000  0.7000  0.7000     1.299  \n",
      "ridge     0.7000  0.7000  0.7000     0.999  \n",
      "knn       0.6999  0.6999  0.6999    13.416  \n",
      "svm       0.6999  0.6999  0.6999     1.367  \n",
      "ada       0.6560  0.6603  0.6620     4.216  \n",
      "rf        0.6000  0.6000  0.6000     2.630  \n",
      "et        0.6000  0.6000  0.6000     2.044  \n",
      "xgboost   0.6000  0.6000  0.6000     2.259  \n",
      "lightgbm  0.6000  0.6000  0.6000     2.723  \n",
      "lda       0.5206  0.5187  0.5303     2.095  \n",
      "qda       0.5000  0.5000  0.5000     0.984  \n",
      "lr        0.2000  0.2000  0.2000     1.136  \n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "best_model = compare_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a69b4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess features & labels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# 1) fill / replace\n",
    "df_downsampled.fillna(0, inplace=True)\n",
    "df_downsampled.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# 2) feature / label split\n",
    "feature_cols = df_downsampled.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# drop any numeric-derived Label columns\n",
    "feature_cols = [c for c in feature_cols if 'label' not in c.lower()]\n",
    "X = df_downsampled[feature_cols].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_downsampled['Label_grp'].values)\n",
    "\n",
    "# 3) scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "348bcbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from torch-geometric) (3.10.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from torch-geometric) (2025.5.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from torch-geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from aiohttp->torch-geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from aiohttp->torch-geometric) (1.11.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->torch-geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->torch-geometric) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\dell\\anaconda3\\envs\\tf\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.13.2)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.3/1.1 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.0/1.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae400ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: 418028 nodes, 2090140 undirected edges\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.sparse import coo_matrix\n",
    "k = 10\n",
    "A = kneighbors_graph(X_scaled, n_neighbors=k,\n",
    "                    mode='connectivity', include_self=False).tocoo()\n",
    "edge_index = torch.tensor([A.row, A.col], dtype=torch.long)\n",
    "\n",
    "data = Data(\n",
    "    x=torch.tensor(X_scaled, dtype=torch.float),\n",
    "    edge_index=edge_index,\n",
    "    y=torch.tensor(y, dtype=torch.long)\n",
    ")\n",
    "print(f\"Graph: {data.num_nodes} nodes, {data.num_edges//2} undirected edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50eda430",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = data.num_nodes\n",
    "idx = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    idx, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask [test_idx] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b83de0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_feats, hid_feats)\n",
    "        self.conv2 = GCNConv(hid_feats, hid_feats)\n",
    "        self.lin   = torch.nn.Linear(hid_feats, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        return F.log_softmax(self.lin(x), dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(data.num_node_features, 64, len(le.classes_)).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "# compute class weights\n",
    "counts = Counter(y)\n",
    "total = sum(counts.values())\n",
    "weights = torch.tensor([total/counts[i] for i in range(len(le.classes_))],\n",
    "                       dtype=torch.float, device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.NLLLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b87c5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss 1.5967 | TrainAcc 0.2278 | TestAcc 0.2297\n",
      "Epoch 002 | Loss 1.2958 | TrainAcc 0.6397 | TestAcc 0.6405\n",
      "Epoch 003 | Loss 1.0877 | TrainAcc 0.6770 | TestAcc 0.6777\n",
      "Epoch 004 | Loss 0.9087 | TrainAcc 0.7208 | TestAcc 0.7214\n",
      "Epoch 005 | Loss 0.7643 | TrainAcc 0.8119 | TestAcc 0.8112\n",
      "Epoch 006 | Loss 0.6516 | TrainAcc 0.8461 | TestAcc 0.8464\n",
      "Epoch 007 | Loss 0.5582 | TrainAcc 0.8460 | TestAcc 0.8462\n",
      "Epoch 008 | Loss 0.4831 | TrainAcc 0.8399 | TestAcc 0.8397\n",
      "Epoch 009 | Loss 0.4252 | TrainAcc 0.8842 | TestAcc 0.8843\n",
      "Epoch 010 | Loss 0.3863 | TrainAcc 0.9047 | TestAcc 0.9043\n",
      "Epoch 011 | Loss 0.3491 | TrainAcc 0.9069 | TestAcc 0.9067\n",
      "Epoch 012 | Loss 0.3196 | TrainAcc 0.9096 | TestAcc 0.9096\n",
      "Epoch 013 | Loss 0.2909 | TrainAcc 0.9228 | TestAcc 0.9234\n",
      "Epoch 014 | Loss 0.2767 | TrainAcc 0.9358 | TestAcc 0.9363\n",
      "Epoch 015 | Loss 0.2525 | TrainAcc 0.9347 | TestAcc 0.9348\n",
      "Epoch 016 | Loss 0.2410 | TrainAcc 0.9301 | TestAcc 0.9299\n",
      "Epoch 017 | Loss 0.2297 | TrainAcc 0.9381 | TestAcc 0.9378\n",
      "Epoch 018 | Loss 0.2204 | TrainAcc 0.9461 | TestAcc 0.9459\n",
      "Epoch 019 | Loss 0.2100 | TrainAcc 0.9434 | TestAcc 0.9435\n",
      "Epoch 020 | Loss 0.1996 | TrainAcc 0.9444 | TestAcc 0.9446\n",
      "Epoch 021 | Loss 0.1910 | TrainAcc 0.9484 | TestAcc 0.9483\n",
      "Epoch 022 | Loss 0.1822 | TrainAcc 0.9465 | TestAcc 0.9466\n",
      "Epoch 023 | Loss 0.1760 | TrainAcc 0.9472 | TestAcc 0.9471\n",
      "Epoch 024 | Loss 0.1718 | TrainAcc 0.9547 | TestAcc 0.9545\n",
      "Epoch 025 | Loss 0.1655 | TrainAcc 0.9498 | TestAcc 0.9500\n",
      "Epoch 026 | Loss 0.1597 | TrainAcc 0.9526 | TestAcc 0.9527\n",
      "Epoch 027 | Loss 0.1572 | TrainAcc 0.9580 | TestAcc 0.9577\n",
      "Epoch 028 | Loss 0.1509 | TrainAcc 0.9512 | TestAcc 0.9514\n",
      "Epoch 029 | Loss 0.1482 | TrainAcc 0.9498 | TestAcc 0.9502\n",
      "Epoch 030 | Loss 0.1446 | TrainAcc 0.9620 | TestAcc 0.9617\n",
      "Epoch 031 | Loss 0.1388 | TrainAcc 0.9603 | TestAcc 0.9598\n",
      "Epoch 032 | Loss 0.1363 | TrainAcc 0.9544 | TestAcc 0.9545\n",
      "Epoch 033 | Loss 0.1328 | TrainAcc 0.9608 | TestAcc 0.9604\n",
      "Epoch 034 | Loss 0.1312 | TrainAcc 0.9636 | TestAcc 0.9633\n",
      "Epoch 035 | Loss 0.1284 | TrainAcc 0.9643 | TestAcc 0.9639\n",
      "Epoch 036 | Loss 0.1242 | TrainAcc 0.9651 | TestAcc 0.9648\n",
      "Epoch 037 | Loss 0.1262 | TrainAcc 0.9664 | TestAcc 0.9665\n",
      "Epoch 038 | Loss 0.1231 | TrainAcc 0.9599 | TestAcc 0.9596\n",
      "Epoch 039 | Loss 0.1191 | TrainAcc 0.9691 | TestAcc 0.9692\n",
      "Epoch 040 | Loss 0.1162 | TrainAcc 0.9696 | TestAcc 0.9696\n",
      "Epoch 041 | Loss 0.1133 | TrainAcc 0.9641 | TestAcc 0.9642\n",
      "Epoch 042 | Loss 0.1180 | TrainAcc 0.9674 | TestAcc 0.9674\n",
      "Epoch 043 | Loss 0.1081 | TrainAcc 0.9672 | TestAcc 0.9674\n",
      "Epoch 044 | Loss 0.1073 | TrainAcc 0.9696 | TestAcc 0.9695\n",
      "Epoch 045 | Loss 0.1062 | TrainAcc 0.9695 | TestAcc 0.9695\n",
      "Epoch 046 | Loss 0.1036 | TrainAcc 0.9675 | TestAcc 0.9678\n",
      "Epoch 047 | Loss 0.1031 | TrainAcc 0.9692 | TestAcc 0.9694\n",
      "Epoch 048 | Loss 0.1027 | TrainAcc 0.9671 | TestAcc 0.9674\n",
      "Epoch 049 | Loss 0.1005 | TrainAcc 0.9718 | TestAcc 0.9718\n",
      "Epoch 050 | Loss 0.0995 | TrainAcc 0.9728 | TestAcc 0.9726\n",
      "Epoch 051 | Loss 0.0974 | TrainAcc 0.9682 | TestAcc 0.9682\n",
      "Epoch 052 | Loss 0.0976 | TrainAcc 0.9699 | TestAcc 0.9701\n",
      "Epoch 053 | Loss 0.0948 | TrainAcc 0.9699 | TestAcc 0.9701\n",
      "Epoch 054 | Loss 0.0943 | TrainAcc 0.9735 | TestAcc 0.9735\n",
      "Epoch 055 | Loss 0.0926 | TrainAcc 0.9726 | TestAcc 0.9727\n",
      "Epoch 056 | Loss 0.0911 | TrainAcc 0.9702 | TestAcc 0.9702\n",
      "Epoch 057 | Loss 0.0928 | TrainAcc 0.9727 | TestAcc 0.9726\n",
      "Epoch 058 | Loss 0.0910 | TrainAcc 0.9690 | TestAcc 0.9692\n",
      "Epoch 059 | Loss 0.0896 | TrainAcc 0.9742 | TestAcc 0.9743\n",
      "Epoch 060 | Loss 0.0890 | TrainAcc 0.9748 | TestAcc 0.9750\n",
      "Epoch 061 | Loss 0.0869 | TrainAcc 0.9703 | TestAcc 0.9703\n",
      "Epoch 062 | Loss 0.0893 | TrainAcc 0.9727 | TestAcc 0.9727\n",
      "Epoch 063 | Loss 0.0857 | TrainAcc 0.9719 | TestAcc 0.9719\n",
      "Epoch 064 | Loss 0.0855 | TrainAcc 0.9758 | TestAcc 0.9759\n",
      "Epoch 065 | Loss 0.0850 | TrainAcc 0.9755 | TestAcc 0.9756\n",
      "Epoch 066 | Loss 0.0833 | TrainAcc 0.9729 | TestAcc 0.9731\n",
      "Epoch 067 | Loss 0.0820 | TrainAcc 0.9749 | TestAcc 0.9752\n",
      "Epoch 068 | Loss 0.0817 | TrainAcc 0.9754 | TestAcc 0.9756\n",
      "Epoch 069 | Loss 0.0805 | TrainAcc 0.9737 | TestAcc 0.9738\n",
      "Epoch 070 | Loss 0.0802 | TrainAcc 0.9756 | TestAcc 0.9760\n",
      "Epoch 071 | Loss 0.0789 | TrainAcc 0.9757 | TestAcc 0.9760\n",
      "Epoch 072 | Loss 0.0787 | TrainAcc 0.9735 | TestAcc 0.9737\n",
      "Epoch 073 | Loss 0.0776 | TrainAcc 0.9750 | TestAcc 0.9752\n",
      "Epoch 074 | Loss 0.0773 | TrainAcc 0.9764 | TestAcc 0.9770\n",
      "Epoch 075 | Loss 0.0768 | TrainAcc 0.9751 | TestAcc 0.9752\n",
      "Epoch 076 | Loss 0.0757 | TrainAcc 0.9755 | TestAcc 0.9756\n",
      "Epoch 077 | Loss 0.0755 | TrainAcc 0.9768 | TestAcc 0.9771\n",
      "Epoch 078 | Loss 0.0756 | TrainAcc 0.9744 | TestAcc 0.9745\n",
      "Epoch 079 | Loss 0.0743 | TrainAcc 0.9764 | TestAcc 0.9766\n",
      "Epoch 080 | Loss 0.0739 | TrainAcc 0.9764 | TestAcc 0.9767\n",
      "Epoch 081 | Loss 0.0739 | TrainAcc 0.9738 | TestAcc 0.9743\n",
      "Epoch 082 | Loss 0.0734 | TrainAcc 0.9769 | TestAcc 0.9773\n",
      "Epoch 083 | Loss 0.0761 | TrainAcc 0.9750 | TestAcc 0.9752\n",
      "Epoch 084 | Loss 0.0774 | TrainAcc 0.9765 | TestAcc 0.9770\n",
      "Epoch 085 | Loss 0.0764 | TrainAcc 0.9761 | TestAcc 0.9765\n",
      "Epoch 086 | Loss 0.0750 | TrainAcc 0.9753 | TestAcc 0.9754\n",
      "Epoch 087 | Loss 0.0730 | TrainAcc 0.9770 | TestAcc 0.9772\n",
      "Epoch 088 | Loss 0.0726 | TrainAcc 0.9764 | TestAcc 0.9767\n",
      "Epoch 089 | Loss 0.0751 | TrainAcc 0.9727 | TestAcc 0.9729\n",
      "Epoch 090 | Loss 0.0739 | TrainAcc 0.9777 | TestAcc 0.9782\n",
      "Epoch 091 | Loss 0.0697 | TrainAcc 0.9765 | TestAcc 0.9768\n",
      "Epoch 092 | Loss 0.0709 | TrainAcc 0.9743 | TestAcc 0.9746\n",
      "Epoch 093 | Loss 0.0744 | TrainAcc 0.9782 | TestAcc 0.9785\n",
      "Epoch 094 | Loss 0.0712 | TrainAcc 0.9753 | TestAcc 0.9755\n",
      "Epoch 095 | Loss 0.0735 | TrainAcc 0.9768 | TestAcc 0.9770\n",
      "Epoch 096 | Loss 0.0737 | TrainAcc 0.9769 | TestAcc 0.9773\n",
      "Epoch 097 | Loss 0.0721 | TrainAcc 0.9752 | TestAcc 0.9755\n",
      "Epoch 098 | Loss 0.0688 | TrainAcc 0.9778 | TestAcc 0.9781\n",
      "Epoch 099 | Loss 0.0705 | TrainAcc 0.9775 | TestAcc 0.9776\n",
      "Epoch 100 | Loss 0.0716 | TrainAcc 0.9739 | TestAcc 0.9742\n",
      "Epoch 101 | Loss 0.0683 | TrainAcc 0.9785 | TestAcc 0.9788\n",
      "Epoch 102 | Loss 0.0706 | TrainAcc 0.9809 | TestAcc 0.9810\n",
      "Epoch 103 | Loss 0.0690 | TrainAcc 0.9751 | TestAcc 0.9754\n",
      "Epoch 104 | Loss 0.0678 | TrainAcc 0.9754 | TestAcc 0.9757\n",
      "Epoch 105 | Loss 0.0677 | TrainAcc 0.9777 | TestAcc 0.9778\n",
      "Epoch 106 | Loss 0.0667 | TrainAcc 0.9768 | TestAcc 0.9770\n",
      "Epoch 107 | Loss 0.0673 | TrainAcc 0.9766 | TestAcc 0.9768\n",
      "Epoch 108 | Loss 0.0660 | TrainAcc 0.9789 | TestAcc 0.9792\n",
      "Epoch 109 | Loss 0.0648 | TrainAcc 0.9785 | TestAcc 0.9788\n",
      "Epoch 110 | Loss 0.0659 | TrainAcc 0.9766 | TestAcc 0.9768\n",
      "Epoch 111 | Loss 0.0660 | TrainAcc 0.9758 | TestAcc 0.9761\n",
      "Epoch 112 | Loss 0.0677 | TrainAcc 0.9804 | TestAcc 0.9805\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "history = {'loss': [], 'train_acc': [], 'test_acc': []}\n",
    "best_test, patience, stall = 0.0, 10, 0\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    pred = out.argmax(dim=1)\n",
    "    train_acc = pred[data.train_mask].eq(data.y[data.train_mask]).float().mean().item()\n",
    "    test_acc  = pred[data.test_mask].eq(data.y[data.test_mask]).float().mean().item()\n",
    "\n",
    "    history['loss'].append(loss.item())\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_acc'].append(test_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Loss {loss:.4f} | \"\n",
    "          f\"TrainAcc {train_acc:.4f} | TestAcc {test_acc:.4f}\")\n",
    "\n",
    "    if test_acc > best_test:\n",
    "        best_test, stall = test_acc, 0\n",
    "    else:\n",
    "        stall += 1\n",
    "        if stall >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9c3e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chia dữ liệu train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Chuyển sang tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "X_test  = torch.tensor(X_test, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb4ddf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hid_dim)\n",
    "        self.fc2 = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc3 = nn.Linear(hid_dim, out_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ANN(X_train.shape[1], 64, len(np.unique(y))).to(device)\n",
    "X_train, X_test = X_train.to(device), X_test.to(device)\n",
    "y_train, y_test = y_train.to(device), y_test.to(device)\n",
    "\n",
    "# Loss và optimizer\n",
    "class_counts = torch.bincount(y_train)\n",
    "weights = (1.0 / class_counts.float()).to(device)\n",
    "criterion = nn.NLLLoss(weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cd16bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss 0.0405 | TrainAcc 0.9874 | TestAcc 0.9870\n",
      "Epoch 002 | Loss 0.0404 | TrainAcc 0.9874 | TestAcc 0.9870\n",
      "Epoch 003 | Loss 0.0404 | TrainAcc 0.9874 | TestAcc 0.9870\n",
      "Epoch 004 | Loss 0.0403 | TrainAcc 0.9874 | TestAcc 0.9870\n",
      "Epoch 005 | Loss 0.0402 | TrainAcc 0.9874 | TestAcc 0.9870\n",
      "Epoch 006 | Loss 0.0401 | TrainAcc 0.9874 | TestAcc 0.9871\n",
      "Epoch 007 | Loss 0.0400 | TrainAcc 0.9875 | TestAcc 0.9871\n",
      "Epoch 008 | Loss 0.0399 | TrainAcc 0.9875 | TestAcc 0.9872\n",
      "Epoch 009 | Loss 0.0398 | TrainAcc 0.9875 | TestAcc 0.9872\n",
      "Epoch 010 | Loss 0.0397 | TrainAcc 0.9875 | TestAcc 0.9873\n",
      "Epoch 011 | Loss 0.0396 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 012 | Loss 0.0395 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 013 | Loss 0.0394 | TrainAcc 0.9876 | TestAcc 0.9873\n",
      "Epoch 014 | Loss 0.0394 | TrainAcc 0.9876 | TestAcc 0.9873\n",
      "Epoch 015 | Loss 0.0393 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 016 | Loss 0.0393 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 017 | Loss 0.0392 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 018 | Loss 0.0391 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 019 | Loss 0.0391 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 020 | Loss 0.0390 | TrainAcc 0.9876 | TestAcc 0.9873\n",
      "Epoch 021 | Loss 0.0390 | TrainAcc 0.9876 | TestAcc 0.9873\n",
      "Epoch 022 | Loss 0.0389 | TrainAcc 0.9876 | TestAcc 0.9873\n",
      "Epoch 023 | Loss 0.0389 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 024 | Loss 0.0388 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 025 | Loss 0.0388 | TrainAcc 0.9876 | TestAcc 0.9873\n",
      "Epoch 026 | Loss 0.0387 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 027 | Loss 0.0387 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 028 | Loss 0.0386 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 029 | Loss 0.0386 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 030 | Loss 0.0385 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 031 | Loss 0.0384 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 032 | Loss 0.0384 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 033 | Loss 0.0383 | TrainAcc 0.9876 | TestAcc 0.9874\n",
      "Epoch 034 | Loss 0.0383 | TrainAcc 0.9877 | TestAcc 0.9875\n",
      "Epoch 035 | Loss 0.0382 | TrainAcc 0.9877 | TestAcc 0.9875\n",
      "Epoch 036 | Loss 0.0382 | TrainAcc 0.9877 | TestAcc 0.9875\n",
      "Epoch 037 | Loss 0.0381 | TrainAcc 0.9877 | TestAcc 0.9875\n",
      "Epoch 038 | Loss 0.0381 | TrainAcc 0.9877 | TestAcc 0.9875\n",
      "Epoch 039 | Loss 0.0380 | TrainAcc 0.9877 | TestAcc 0.9875\n",
      "Epoch 040 | Loss 0.0380 | TrainAcc 0.9877 | TestAcc 0.9876\n",
      "Epoch 041 | Loss 0.0380 | TrainAcc 0.9878 | TestAcc 0.9875\n",
      "Epoch 042 | Loss 0.0379 | TrainAcc 0.9877 | TestAcc 0.9876\n",
      "Epoch 043 | Loss 0.0379 | TrainAcc 0.9879 | TestAcc 0.9876\n",
      "Epoch 044 | Loss 0.0378 | TrainAcc 0.9879 | TestAcc 0.9876\n",
      "Epoch 045 | Loss 0.0378 | TrainAcc 0.9879 | TestAcc 0.9877\n",
      "Epoch 046 | Loss 0.0377 | TrainAcc 0.9879 | TestAcc 0.9877\n",
      "Epoch 047 | Loss 0.0377 | TrainAcc 0.9879 | TestAcc 0.9877\n",
      "Epoch 048 | Loss 0.0376 | TrainAcc 0.9879 | TestAcc 0.9878\n",
      "Epoch 049 | Loss 0.0376 | TrainAcc 0.9879 | TestAcc 0.9878\n",
      "Epoch 050 | Loss 0.0375 | TrainAcc 0.9879 | TestAcc 0.9878\n",
      "Epoch 051 | Loss 0.0375 | TrainAcc 0.9880 | TestAcc 0.9879\n",
      "Epoch 052 | Loss 0.0374 | TrainAcc 0.9880 | TestAcc 0.9880\n",
      "Epoch 053 | Loss 0.0374 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 054 | Loss 0.0373 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 055 | Loss 0.0373 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 056 | Loss 0.0372 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 057 | Loss 0.0372 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 058 | Loss 0.0372 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 059 | Loss 0.0371 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 060 | Loss 0.0371 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 061 | Loss 0.0370 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 062 | Loss 0.0370 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 063 | Loss 0.0369 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 064 | Loss 0.0369 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 065 | Loss 0.0369 | TrainAcc 0.9880 | TestAcc 0.9879\n",
      "Epoch 066 | Loss 0.0368 | TrainAcc 0.9880 | TestAcc 0.9879\n",
      "Epoch 067 | Loss 0.0368 | TrainAcc 0.9880 | TestAcc 0.9879\n",
      "Epoch 068 | Loss 0.0367 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 069 | Loss 0.0367 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 070 | Loss 0.0367 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 071 | Loss 0.0366 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 072 | Loss 0.0366 | TrainAcc 0.9881 | TestAcc 0.9879\n",
      "Epoch 073 | Loss 0.0366 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 074 | Loss 0.0365 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 075 | Loss 0.0365 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 076 | Loss 0.0364 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 077 | Loss 0.0364 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 078 | Loss 0.0364 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 079 | Loss 0.0363 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 080 | Loss 0.0363 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 081 | Loss 0.0363 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 082 | Loss 0.0362 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 083 | Loss 0.0362 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 084 | Loss 0.0361 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 085 | Loss 0.0361 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 086 | Loss 0.0361 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 087 | Loss 0.0360 | TrainAcc 0.9881 | TestAcc 0.9880\n",
      "Epoch 088 | Loss 0.0360 | TrainAcc 0.9881 | TestAcc 0.9881\n",
      "Epoch 089 | Loss 0.0360 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 090 | Loss 0.0359 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 091 | Loss 0.0359 | TrainAcc 0.9881 | TestAcc 0.9881\n",
      "Epoch 092 | Loss 0.0359 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 093 | Loss 0.0358 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 094 | Loss 0.0358 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 095 | Loss 0.0358 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 096 | Loss 0.0357 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 097 | Loss 0.0357 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 098 | Loss 0.0357 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 099 | Loss 0.0356 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 100 | Loss 0.0356 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 101 | Loss 0.0356 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 102 | Loss 0.0355 | TrainAcc 0.9882 | TestAcc 0.9881\n",
      "Epoch 103 | Loss 0.0355 | TrainAcc 0.9883 | TestAcc 0.9881\n",
      "Epoch 104 | Loss 0.0355 | TrainAcc 0.9883 | TestAcc 0.9882\n",
      "Epoch 105 | Loss 0.0354 | TrainAcc 0.9883 | TestAcc 0.9882\n",
      "Epoch 106 | Loss 0.0354 | TrainAcc 0.9883 | TestAcc 0.9882\n",
      "Epoch 107 | Loss 0.0354 | TrainAcc 0.9883 | TestAcc 0.9882\n",
      "Epoch 108 | Loss 0.0353 | TrainAcc 0.9883 | TestAcc 0.9882\n",
      "Epoch 109 | Loss 0.0353 | TrainAcc 0.9883 | TestAcc 0.9882\n",
      "Epoch 110 | Loss 0.0353 | TrainAcc 0.9883 | TestAcc 0.9882\n",
      "Epoch 111 | Loss 0.0352 | TrainAcc 0.9883 | TestAcc 0.9882\n",
      "Epoch 112 | Loss 0.0352 | TrainAcc 0.9883 | TestAcc 0.9882\n",
      "Epoch 113 | Loss 0.0352 | TrainAcc 0.9884 | TestAcc 0.9882\n",
      "Epoch 114 | Loss 0.0351 | TrainAcc 0.9884 | TestAcc 0.9882\n",
      "Epoch 115 | Loss 0.0351 | TrainAcc 0.9884 | TestAcc 0.9883\n",
      "Epoch 116 | Loss 0.0351 | TrainAcc 0.9884 | TestAcc 0.9883\n",
      "Epoch 117 | Loss 0.0350 | TrainAcc 0.9884 | TestAcc 0.9883\n",
      "Epoch 118 | Loss 0.0350 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 119 | Loss 0.0350 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 120 | Loss 0.0349 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 121 | Loss 0.0349 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 122 | Loss 0.0349 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 123 | Loss 0.0348 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 124 | Loss 0.0348 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 125 | Loss 0.0348 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 126 | Loss 0.0347 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 127 | Loss 0.0347 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 128 | Loss 0.0347 | TrainAcc 0.9885 | TestAcc 0.9883\n",
      "Epoch 129 | Loss 0.0347 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 130 | Loss 0.0346 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 131 | Loss 0.0346 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 132 | Loss 0.0346 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 133 | Loss 0.0345 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 134 | Loss 0.0345 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 135 | Loss 0.0345 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 136 | Loss 0.0344 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 137 | Loss 0.0344 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 138 | Loss 0.0344 | TrainAcc 0.9886 | TestAcc 0.9884\n",
      "Epoch 139 | Loss 0.0343 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 140 | Loss 0.0343 | TrainAcc 0.9885 | TestAcc 0.9884\n",
      "Epoch 141 | Loss 0.0343 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 142 | Loss 0.0343 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 143 | Loss 0.0342 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 144 | Loss 0.0342 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 145 | Loss 0.0342 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 146 | Loss 0.0341 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 147 | Loss 0.0341 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 148 | Loss 0.0341 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 149 | Loss 0.0341 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 150 | Loss 0.0340 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 151 | Loss 0.0340 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 152 | Loss 0.0340 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 153 | Loss 0.0339 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 154 | Loss 0.0339 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 155 | Loss 0.0339 | TrainAcc 0.9886 | TestAcc 0.9885\n",
      "Epoch 156 | Loss 0.0338 | TrainAcc 0.9887 | TestAcc 0.9885\n",
      "Epoch 157 | Loss 0.0338 | TrainAcc 0.9887 | TestAcc 0.9885\n",
      "Epoch 158 | Loss 0.0338 | TrainAcc 0.9887 | TestAcc 0.9885\n",
      "Epoch 159 | Loss 0.0338 | TrainAcc 0.9887 | TestAcc 0.9885\n",
      "Epoch 160 | Loss 0.0337 | TrainAcc 0.9887 | TestAcc 0.9885\n",
      "Epoch 161 | Loss 0.0337 | TrainAcc 0.9887 | TestAcc 0.9885\n",
      "Epoch 162 | Loss 0.0337 | TrainAcc 0.9887 | TestAcc 0.9886\n",
      "Epoch 163 | Loss 0.0336 | TrainAcc 0.9887 | TestAcc 0.9886\n",
      "Epoch 164 | Loss 0.0336 | TrainAcc 0.9887 | TestAcc 0.9886\n",
      "Epoch 165 | Loss 0.0336 | TrainAcc 0.9887 | TestAcc 0.9886\n",
      "Epoch 166 | Loss 0.0336 | TrainAcc 0.9887 | TestAcc 0.9886\n",
      "Epoch 167 | Loss 0.0335 | TrainAcc 0.9887 | TestAcc 0.9886\n",
      "Epoch 168 | Loss 0.0335 | TrainAcc 0.9887 | TestAcc 0.9887\n",
      "Epoch 169 | Loss 0.0335 | TrainAcc 0.9887 | TestAcc 0.9886\n",
      "Epoch 170 | Loss 0.0334 | TrainAcc 0.9887 | TestAcc 0.9886\n",
      "Epoch 171 | Loss 0.0334 | TrainAcc 0.9887 | TestAcc 0.9886\n",
      "Epoch 172 | Loss 0.0334 | TrainAcc 0.9887 | TestAcc 0.9887\n",
      "Epoch 173 | Loss 0.0333 | TrainAcc 0.9888 | TestAcc 0.9887\n",
      "Epoch 174 | Loss 0.0333 | TrainAcc 0.9888 | TestAcc 0.9887\n",
      "Epoch 175 | Loss 0.0333 | TrainAcc 0.9888 | TestAcc 0.9887\n",
      "Epoch 176 | Loss 0.0333 | TrainAcc 0.9888 | TestAcc 0.9887\n",
      "Epoch 177 | Loss 0.0332 | TrainAcc 0.9888 | TestAcc 0.9887\n",
      "Epoch 178 | Loss 0.0332 | TrainAcc 0.9888 | TestAcc 0.9887\n",
      "Epoch 179 | Loss 0.0332 | TrainAcc 0.9888 | TestAcc 0.9887\n",
      "Epoch 180 | Loss 0.0331 | TrainAcc 0.9888 | TestAcc 0.9887\n",
      "Epoch 181 | Loss 0.0331 | TrainAcc 0.9888 | TestAcc 0.9887\n",
      "Epoch 182 | Loss 0.0331 | TrainAcc 0.9888 | TestAcc 0.9888\n",
      "Epoch 183 | Loss 0.0330 | TrainAcc 0.9888 | TestAcc 0.9888\n",
      "Epoch 184 | Loss 0.0330 | TrainAcc 0.9889 | TestAcc 0.9888\n",
      "Epoch 185 | Loss 0.0330 | TrainAcc 0.9888 | TestAcc 0.9888\n",
      "Epoch 186 | Loss 0.0329 | TrainAcc 0.9888 | TestAcc 0.9888\n",
      "Epoch 187 | Loss 0.0329 | TrainAcc 0.9889 | TestAcc 0.9888\n",
      "Epoch 188 | Loss 0.0329 | TrainAcc 0.9889 | TestAcc 0.9888\n",
      "Epoch 189 | Loss 0.0328 | TrainAcc 0.9889 | TestAcc 0.9888\n",
      "Epoch 190 | Loss 0.0328 | TrainAcc 0.9889 | TestAcc 0.9888\n",
      "Epoch 191 | Loss 0.0328 | TrainAcc 0.9889 | TestAcc 0.9889\n",
      "Epoch 192 | Loss 0.0328 | TrainAcc 0.9889 | TestAcc 0.9889\n",
      "Epoch 193 | Loss 0.0327 | TrainAcc 0.9889 | TestAcc 0.9889\n",
      "Epoch 194 | Loss 0.0327 | TrainAcc 0.9889 | TestAcc 0.9889\n",
      "Epoch 195 | Loss 0.0327 | TrainAcc 0.9889 | TestAcc 0.9889\n",
      "Epoch 196 | Loss 0.0326 | TrainAcc 0.9889 | TestAcc 0.9889\n",
      "Epoch 197 | Loss 0.0326 | TrainAcc 0.9889 | TestAcc 0.9889\n",
      "Epoch 198 | Loss 0.0326 | TrainAcc 0.9889 | TestAcc 0.9889\n",
      "Epoch 199 | Loss 0.0326 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 200 | Loss 0.0325 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 201 | Loss 0.0325 | TrainAcc 0.9889 | TestAcc 0.9889\n",
      "Epoch 202 | Loss 0.0325 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 203 | Loss 0.0324 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 204 | Loss 0.0324 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 205 | Loss 0.0324 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 206 | Loss 0.0324 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 207 | Loss 0.0323 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 208 | Loss 0.0323 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 209 | Loss 0.0323 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 210 | Loss 0.0322 | TrainAcc 0.9890 | TestAcc 0.9890\n",
      "Epoch 211 | Loss 0.0322 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 212 | Loss 0.0322 | TrainAcc 0.9890 | TestAcc 0.9889\n",
      "Epoch 213 | Loss 0.0322 | TrainAcc 0.9890 | TestAcc 0.9890\n",
      "Epoch 214 | Loss 0.0321 | TrainAcc 0.9890 | TestAcc 0.9890\n",
      "Epoch 215 | Loss 0.0321 | TrainAcc 0.9890 | TestAcc 0.9890\n",
      "Epoch 216 | Loss 0.0321 | TrainAcc 0.9890 | TestAcc 0.9890\n",
      "Epoch 217 | Loss 0.0320 | TrainAcc 0.9890 | TestAcc 0.9890\n",
      "Epoch 218 | Loss 0.0320 | TrainAcc 0.9890 | TestAcc 0.9891\n",
      "Epoch 219 | Loss 0.0320 | TrainAcc 0.9891 | TestAcc 0.9891\n",
      "Epoch 220 | Loss 0.0319 | TrainAcc 0.9891 | TestAcc 0.9891\n",
      "Epoch 221 | Loss 0.0319 | TrainAcc 0.9891 | TestAcc 0.9891\n",
      "Epoch 222 | Loss 0.0319 | TrainAcc 0.9891 | TestAcc 0.9891\n",
      "Epoch 223 | Loss 0.0319 | TrainAcc 0.9891 | TestAcc 0.9891\n",
      "Epoch 224 | Loss 0.0318 | TrainAcc 0.9891 | TestAcc 0.9891\n",
      "Epoch 225 | Loss 0.0318 | TrainAcc 0.9891 | TestAcc 0.9891\n",
      "Epoch 226 | Loss 0.0318 | TrainAcc 0.9891 | TestAcc 0.9891\n",
      "Epoch 227 | Loss 0.0317 | TrainAcc 0.9891 | TestAcc 0.9892\n",
      "Epoch 228 | Loss 0.0317 | TrainAcc 0.9892 | TestAcc 0.9892\n",
      "Epoch 229 | Loss 0.0317 | TrainAcc 0.9892 | TestAcc 0.9892\n",
      "Epoch 230 | Loss 0.0317 | TrainAcc 0.9892 | TestAcc 0.9892\n",
      "Epoch 231 | Loss 0.0316 | TrainAcc 0.9892 | TestAcc 0.9892\n",
      "Epoch 232 | Loss 0.0316 | TrainAcc 0.9892 | TestAcc 0.9892\n",
      "Epoch 233 | Loss 0.0316 | TrainAcc 0.9892 | TestAcc 0.9892\n",
      "Epoch 234 | Loss 0.0315 | TrainAcc 0.9892 | TestAcc 0.9892\n",
      "Epoch 235 | Loss 0.0315 | TrainAcc 0.9892 | TestAcc 0.9892\n",
      "Epoch 236 | Loss 0.0315 | TrainAcc 0.9892 | TestAcc 0.9892\n",
      "Epoch 237 | Loss 0.0314 | TrainAcc 0.9892 | TestAcc 0.9893\n",
      "Epoch 238 | Loss 0.0314 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 239 | Loss 0.0314 | TrainAcc 0.9892 | TestAcc 0.9893\n",
      "Epoch 240 | Loss 0.0314 | TrainAcc 0.9892 | TestAcc 0.9893\n",
      "Epoch 241 | Loss 0.0313 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 242 | Loss 0.0313 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 243 | Loss 0.0313 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 244 | Loss 0.0312 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 245 | Loss 0.0312 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 246 | Loss 0.0312 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 247 | Loss 0.0311 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 248 | Loss 0.0311 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 249 | Loss 0.0311 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 250 | Loss 0.0310 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 251 | Loss 0.0310 | TrainAcc 0.9893 | TestAcc 0.9894\n",
      "Epoch 252 | Loss 0.0310 | TrainAcc 0.9893 | TestAcc 0.9894\n",
      "Epoch 253 | Loss 0.0309 | TrainAcc 0.9893 | TestAcc 0.9894\n",
      "Epoch 254 | Loss 0.0309 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 255 | Loss 0.0309 | TrainAcc 0.9893 | TestAcc 0.9893\n",
      "Epoch 256 | Loss 0.0308 | TrainAcc 0.9893 | TestAcc 0.9894\n",
      "Epoch 257 | Loss 0.0308 | TrainAcc 0.9893 | TestAcc 0.9894\n",
      "Epoch 258 | Loss 0.0308 | TrainAcc 0.9893 | TestAcc 0.9894\n",
      "Epoch 259 | Loss 0.0308 | TrainAcc 0.9894 | TestAcc 0.9894\n",
      "Epoch 260 | Loss 0.0307 | TrainAcc 0.9894 | TestAcc 0.9894\n",
      "Epoch 261 | Loss 0.0307 | TrainAcc 0.9893 | TestAcc 0.9894\n",
      "Epoch 262 | Loss 0.0307 | TrainAcc 0.9894 | TestAcc 0.9894\n",
      "Epoch 263 | Loss 0.0306 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 264 | Loss 0.0306 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 265 | Loss 0.0306 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 266 | Loss 0.0305 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 267 | Loss 0.0305 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 268 | Loss 0.0305 | TrainAcc 0.9894 | TestAcc 0.9894\n",
      "Epoch 269 | Loss 0.0305 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 270 | Loss 0.0304 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 271 | Loss 0.0304 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 272 | Loss 0.0304 | TrainAcc 0.9895 | TestAcc 0.9894\n",
      "Epoch 273 | Loss 0.0303 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 274 | Loss 0.0303 | TrainAcc 0.9895 | TestAcc 0.9895\n",
      "Epoch 275 | Loss 0.0303 | TrainAcc 0.9894 | TestAcc 0.9895\n",
      "Epoch 276 | Loss 0.0302 | TrainAcc 0.9895 | TestAcc 0.9895\n",
      "Epoch 277 | Loss 0.0302 | TrainAcc 0.9895 | TestAcc 0.9895\n",
      "Epoch 278 | Loss 0.0302 | TrainAcc 0.9895 | TestAcc 0.9895\n",
      "Epoch 279 | Loss 0.0301 | TrainAcc 0.9895 | TestAcc 0.9894\n",
      "Epoch 280 | Loss 0.0301 | TrainAcc 0.9894 | TestAcc 0.9896\n",
      "Epoch 281 | Loss 0.0301 | TrainAcc 0.9895 | TestAcc 0.9895\n",
      "Epoch 282 | Loss 0.0301 | TrainAcc 0.9895 | TestAcc 0.9896\n",
      "Epoch 283 | Loss 0.0300 | TrainAcc 0.9896 | TestAcc 0.9894\n",
      "Epoch 284 | Loss 0.0300 | TrainAcc 0.9894 | TestAcc 0.9897\n",
      "Epoch 285 | Loss 0.0300 | TrainAcc 0.9896 | TestAcc 0.9895\n",
      "Epoch 286 | Loss 0.0299 | TrainAcc 0.9895 | TestAcc 0.9896\n",
      "Epoch 287 | Loss 0.0299 | TrainAcc 0.9896 | TestAcc 0.9895\n",
      "Epoch 288 | Loss 0.0299 | TrainAcc 0.9895 | TestAcc 0.9895\n",
      "Epoch 289 | Loss 0.0298 | TrainAcc 0.9895 | TestAcc 0.9895\n",
      "Epoch 290 | Loss 0.0298 | TrainAcc 0.9895 | TestAcc 0.9895\n",
      "Epoch 291 | Loss 0.0297 | TrainAcc 0.9895 | TestAcc 0.9896\n",
      "Epoch 292 | Loss 0.0297 | TrainAcc 0.9896 | TestAcc 0.9895\n",
      "Epoch 293 | Loss 0.0297 | TrainAcc 0.9895 | TestAcc 0.9897\n",
      "Epoch 294 | Loss 0.0296 | TrainAcc 0.9896 | TestAcc 0.9895\n",
      "Epoch 295 | Loss 0.0296 | TrainAcc 0.9894 | TestAcc 0.9898\n",
      "Epoch 296 | Loss 0.0296 | TrainAcc 0.9897 | TestAcc 0.9894\n",
      "Epoch 297 | Loss 0.0296 | TrainAcc 0.9894 | TestAcc 0.9898\n",
      "Epoch 298 | Loss 0.0295 | TrainAcc 0.9897 | TestAcc 0.9894\n",
      "Epoch 299 | Loss 0.0296 | TrainAcc 0.9894 | TestAcc 0.9900\n",
      "Epoch 300 | Loss 0.0295 | TrainAcc 0.9898 | TestAcc 0.9892\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện\n",
    "for epoch in range(1, 301):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(X_train)\n",
    "    loss = criterion(out, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    pred = out.argmax(dim=1)\n",
    "    train_acc = (pred == y_train).float().mean().item()\n",
    "    with torch.no_grad():\n",
    "        test_pred = model(X_test).argmax(dim=1)\n",
    "        test_acc = (test_pred == y_test).float().mean().item()\n",
    "    print(f\"Epoch {epoch:03d} | Loss {loss:.4f} | TrainAcc {train_acc:.4f} | TestAcc {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c0d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     20000\n",
      "           1       1.00      1.00      1.00     20000\n",
      "           2       0.99      1.00      0.99     20000\n",
      "           3       0.91      0.99      0.95      3606\n",
      "           4       0.99      1.00      0.99     20000\n",
      "\n",
      "    accuracy                           0.99     83606\n",
      "   macro avg       0.98      0.99      0.98     83606\n",
      "weighted avg       0.99      0.99      0.99     83606\n",
      "\n",
      "Confusion Matrix:\n",
      " [[19173    11   234   323   259]\n",
      " [   10 19990     0     0     0]\n",
      " [   12     0 19974    13     1]\n",
      " [   14     0    10  3582     0]\n",
      " [    1     0    10     1 19988]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).argmax(dim=1).cpu().numpy()\n",
    "    y_true = y_test.cpu().numpy()\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d107cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vẽ confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "sns.set(style='whitegrid')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c1aa4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: 418028 nodes, 2090140 undirected edges\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Giảm chiều dữ liệu với PCA (ví dụ còn 20 chiều)\n",
    "pca = PCA(n_components=20, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Tạo graph k-NN từ dữ liệu đã giảm chiều\n",
    "k = 10\n",
    "A = kneighbors_graph(X_pca, n_neighbors=k, mode='connectivity', include_self=False).tocoo()\n",
    "edge_index = torch.tensor([A.row, A.col], dtype=torch.long)\n",
    "\n",
    "data = Data(\n",
    "    x=torch.tensor(X_pca, dtype=torch.float),\n",
    "    edge_index=edge_index,\n",
    "    y=torch.tensor(y, dtype=torch.long)\n",
    ")\n",
    "print(f\"Graph: {data.num_nodes} nodes, {data.num_edges//2} undirected edges\")\n",
    "\n",
    "num_nodes = data.num_nodes\n",
    "idx = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    idx, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask [test_idx] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38baaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_feats, hid_feats)\n",
    "        self.conv2 = GCNConv(hid_feats, hid_feats)\n",
    "        self.lin   = torch.nn.Linear(hid_feats, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        return F.log_softmax(self.lin(x), dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(data.num_node_features, 64, len(le.classes_)).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "# compute class weights\n",
    "counts = Counter(y)\n",
    "total = sum(counts.values())\n",
    "weights = torch.tensor([total/counts[i] for i in range(len(le.classes_))],\n",
    "                       dtype=torch.float, device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.NLLLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'loss': [], 'train_acc': [], 'test_acc': []}\n",
    "best_test, patience, stall = 0.0, 10, 0\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    pred = out.argmax(dim=1)\n",
    "    train_acc = pred[data.train_mask].eq(data.y[data.train_mask]).float().mean().item()\n",
    "    test_acc  = pred[data.test_mask].eq(data.y[data.test_mask]).float().mean().item()\n",
    "\n",
    "    history['loss'].append(loss.item())\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_acc'].append(test_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Loss {loss:.4f} | \"\n",
    "          f\"TrainAcc {train_acc:.4f} | TestAcc {test_acc:.4f}\")\n",
    "\n",
    "    if test_acc > best_test:\n",
    "        best_test, stall = test_acc, 0\n",
    "    else:\n",
    "        stall += 1\n",
    "        if stall >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
