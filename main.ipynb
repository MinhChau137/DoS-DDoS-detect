{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cf7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import matplotlib.patches as mpatches\n",
    "import kagglehub\n",
    "import glob\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c630e7",
   "metadata": {},
   "source": [
    "- Tạo class DoSDDoSClassifier với đầy đủ phương pháp:\n",
    "- Triển khai 4 thuật toán ML (KNN, AdaBoost, Random Forest, SVM)\n",
    "- Triển khai 3 kỹ thuật giảm chiều dữ liệu (PCA, Feature Importance, Univariate Selection)\n",
    "- Tiền xử lý dữ liệu (làm sạch, chuẩn hóa MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6636a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoSDDoSClassifier:\n",
    "    \"\"\"\n",
    "    - Thuật toán 4 ml: KNN, AdaBoost, Random Forest, SVM\n",
    "    - 3 Kỹ thuật giảm chiều dữ liệu: PCA, Feature Importance, Univariate Selection\n",
    "    - Hoàn thành tiền xử lý\n",
    "    - Đánh giá với thời gian và độ chính xác\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Thuật toán ML\n",
    "        self.ml_algorithms = {\n",
    "            'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "            'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
    "            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            'SVM': SVC(kernel='rbf', random_state=42)\n",
    "        }\n",
    "        \n",
    "        # Giảm chiều dữ liệu\n",
    "        self.feature_selection_methods = {\n",
    "            'PCA': None,  # Sẽ được khởi tạo động\n",
    "            'Feature_Importance': None,  # ExtraTree + SelectFromModel\n",
    "            'Univariate_Selection': None  # SelectKBest với chi2\n",
    "        }\n",
    "        \n",
    "        # Scaler normalisation MinMax (-1, 1)\n",
    "        self.scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "        # Lưu trữ kết quả và dữ liệu đã giảm chiều\n",
    "        self.results = {}\n",
    "        self.feature_reduced_data = {}\n",
    "        \n",
    "    def preprocess_data(self, X, y, dataset_name=\"Dataset\"):\n",
    "        \"\"\"\n",
    "        Tiền xử lý dữ liệu:\n",
    "        1. Làm sạch giá trị NaN và vô cùng\n",
    "        2. Loại bỏ các features bằng 0\n",
    "        3. Chuẩn hóa MinMax (-1, 1)\n",
    "        4. Encode nhãn\n",
    "        \"\"\"\n",
    "        print(f\"\\nTiền xử lý dữ liệu {dataset_name}...\")\n",
    "        print(f\"   Kích thước ban đầu: {X.shape}\")\n",
    "        \n",
    "        # 1. Làm sạch dữ liệu\n",
    "        X_clean = X.copy()\n",
    "        X_clean = X_clean.replace([np.inf, -np.inf], np.nan)\n",
    "        X_clean = X_clean.fillna(X_clean.mean())\n",
    "\n",
    "        # 2. Loại bỏ các feature bằng 0\n",
    "        non_zero_var_cols = X_clean.columns[(X_clean != 0).any(axis=0)]\n",
    "        X_clean = X_clean[non_zero_var_cols]\n",
    "        \n",
    "        print(f\"   Sau khi làm sạch: {X_clean.shape}\")\n",
    "        \n",
    "        # 3. Chuẩn hóa MinMax (-1, 1)\n",
    "        X_scaled = pd.DataFrame(\n",
    "            self.scaler.fit_transform(X_clean),\n",
    "            columns=X_clean.columns,\n",
    "            index=X_clean.index\n",
    "        )\n",
    "        \n",
    "        # 4. Encode nhãn\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        \n",
    "        print(f\"Tiền xử lý hoàn tất - shape cuối cùng: {X_scaled.shape}\")\n",
    "        return X_scaled, y_encoded\n",
    "    \n",
    "    def apply_feature_selection(self, X_train, X_test, y_train, target_features=None):\n",
    "        \"\"\"\n",
    "        Áp dụng 3 kỹ thuật giảm chiều dữ liệu:\n",
    "        1. PCA (giảm xuống ~50% số feature)\n",
    "        2. Feature Importance (ExtraTree + SelectFromModel)\n",
    "        3. Univariate Selection (SelectKBest với chi2)\n",
    "        \"\"\"\n",
    "        print(f\"\\nÁp dụng các kỹ thuật giảm chiều dữ liệu...\")\n",
    "        \n",
    "        # Tính số lượng features mục tiêu (khoảng 50% theo bài báo)\n",
    "        if target_features is None:\n",
    "            target_features = max(X_train.shape[1] // 2, 10)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # 1. PCA (giảm xuống ~50% số features)\n",
    "        print(f\"PCA: {X_train.shape[1]} → {target_features} features\")\n",
    "        pca = PCA(n_components=target_features)\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "        results['PCA'] = {\n",
    "            'X_train': X_train_pca,\n",
    "            'X_test': X_test_pca,\n",
    "            'n_features': target_features,\n",
    "            'method': pca\n",
    "        }\n",
    "        \n",
    "        # 2. Feature Importance ExtraTree + SelectFromModel\n",
    "        print(f\"Feature Importance: tự động chọn các features tốt nhất\")\n",
    "        extra_tree = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "        extra_tree.fit(X_train, y_train)\n",
    "        selector = SelectFromModel(extra_tree, max_features=target_features)\n",
    "        X_train_fi = selector.fit_transform(X_train, y_train)\n",
    "        X_test_fi = selector.transform(X_test)\n",
    "        results['Feature_Importance'] = {\n",
    "            'X_train': X_train_fi,\n",
    "            'X_test': X_test_fi,\n",
    "            'n_features': X_train_fi.shape[1],\n",
    "            'method': selector\n",
    "        }\n",
    "\n",
    "        # 3. Univariate Selection với chi2 (bài báo trang 3)\n",
    "        print(f\"Univariate Selection: SelectKBest vs chi2\")\n",
    "        # Chuyển đổi thành giá trị dương cho chi2\n",
    "        X_train_pos = X_train - X_train.min() + 0.01\n",
    "        X_test_pos = X_test - X_test.min() + 0.01\n",
    "        \n",
    "        univariate = SelectKBest(score_func=chi2, k=target_features)\n",
    "        X_train_us = univariate.fit_transform(X_train_pos, y_train)\n",
    "        X_test_us = univariate.transform(X_test_pos)\n",
    "        results['Univariate_Selection'] = {\n",
    "            'X_train': X_train_us,\n",
    "            'X_test': X_test_us,\n",
    "            'n_features': target_features,\n",
    "            'method': univariate\n",
    "        }\n",
    "        \n",
    "        print(f\"Hoàn thành giảm chiều dữ liệu\")\n",
    "        return results\n",
    "    \n",
    "    def evaluate_model_combination(self, X_train, X_test, y_train, y_test, \n",
    "                                 ml_name, feature_method_name, dataset_name):\n",
    "        \"\"\"\n",
    "        Đánh giá thời gian và độ chính xác\n",
    "        \"\"\"\n",
    "        # Lấy mô hình ML\n",
    "        model = self.ml_algorithms[ml_name]\n",
    "        \n",
    "        # Huấn luyện vs đo thời gian\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Dự đoán vs đo thời gian\n",
    "        start_time = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        predict_time = time.time() - start_time\n",
    "\n",
    "        # Tính độ chính xác\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Tổng thời gian (huấn luyện + dự đoán) tính bằng mili giây\n",
    "        total_time_ms = (train_time + predict_time) * 1000\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy * 100,  # Phần trăm\n",
    "            'total_time_ms': total_time_ms,\n",
    "            'train_time': train_time,\n",
    "            'predict_time': predict_time,\n",
    "            'y_pred': y_pred\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603cd2b",
   "metadata": {},
   "source": [
    "- Tạo các bộ dữ liệu tổng hợp mô phỏng NSL-KDD 2019, CICIDS 2017 và dữ liệu mô phỏng (đoạn này bỏ qua vì dùng luôn 2 bộ dữ liệu trên kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2feb4f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tạo các bộ dữ liệu tổng hợp dựa trên bài báo...\n",
      "\n",
      "Tạo bộ dữ liệu NSL-KDD 2019...\n",
      "Tạo bộ dữ liệu tổng hợp CICIDS 2017...\n",
      "Tạo bộ dữ liệu mô phỏng...\n"
     ]
    }
   ],
   "source": [
    "#bỏ qua\n",
    "def create_synthetic_datasets():\n",
    "    \"\"\"\n",
    "    Tạo các bộ dữ liệu tổng hợp mô phỏng đặc trưng của 3 bộ dữ liệu trong bài báo:\n",
    "    1. NSL-KDD 2019: ~150,000 mẫu, 42 đặc trưng → 21 sau giảm\n",
    "    2. CICIDS 2017: 68 đặc trưng → 23 sau giảm  \n",
    "    3. Dữ liệu mô phỏng: 45,500 mẫu, 73 đặc trưng → 20 sau giảm\n",
    "    \"\"\"\n",
    "    \n",
    "    datasets = {}\n",
    "    \n",
    "    print(\"Tạo các bộ dữ liệu tổng hợp dựa trên bài báo...\")\n",
    "    \n",
    "    # 1. Dataset simulant NSL-KDD 2019\n",
    "    print(\"\\nTạo bộ dữ liệu NSL-KDD 2019...\")\n",
    "    X_nsl, y_nsl = make_classification(\n",
    "        n_samples=15000,  # số lượng mẫu (article: 150,000)\n",
    "        n_features=42,    \n",
    "        n_informative=35,\n",
    "        n_redundant=5,\n",
    "        n_clusters_per_class=2,\n",
    "        class_sep=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Chuyển đổi sang dữ liệu với tên cột thực tế\n",
    "    nsl_features = [f'feature_{i+1}' for i in range(42)]\n",
    "    X_nsl_df = pd.DataFrame(X_nsl, columns=nsl_features)\n",
    "    y_nsl_labels = ['Normal' if label == 0 else 'Attack' for label in y_nsl]\n",
    "    \n",
    "    datasets['NSL-KDD_2019'] = {\n",
    "        'X': X_nsl_df,\n",
    "        'y': pd.Series(y_nsl_labels),\n",
    "        'description': 'Dataset tổng hợp mô phỏng NSL-KDD 2019 (42→21 đặc trưng)'\n",
    "    }\n",
    "    \n",
    "    # 2. Dataset simulant CICIDS 2017\n",
    "    print(\"Tạo bộ dữ liệu tổng hợp CICIDS 2017...\")\n",
    "    X_cicids, y_cicids = make_classification(\n",
    "        n_samples=12000,  \n",
    "        n_features=68,    \n",
    "        n_informative=55,\n",
    "        n_redundant=8,\n",
    "        n_clusters_per_class=3,\n",
    "        class_sep=0.7,\n",
    "        random_state=123\n",
    "    )\n",
    "\n",
    "    # Mô phỏng các loại tấn công khác nhau\n",
    "    cicids_features = [f'flow_feature_{i+1}' for i in range(68)]\n",
    "    X_cicids_df = pd.DataFrame(X_cicids, columns=cicids_features)\n",
    "\n",
    "    # Tạo nhãn đa lớp để mô phỏng các loại tấn công khác nhau\n",
    "    attack_types = ['Normal', 'DoS', 'DDoS', 'Brute_Force']\n",
    "    y_cicids_multiclass = np.random.choice(attack_types, size=len(y_cicids), p=[0.6, 0.2, 0.15, 0.05])\n",
    "    \n",
    "    datasets['CICIDS_2017'] = {\n",
    "        'X': X_cicids_df,\n",
    "        'y': pd.Series(y_cicids_multiclass),\n",
    "        'description': 'Dataset tổng hợp mô phỏng CICIDS 2017 (68→23 đặc trưng)'\n",
    "    }\n",
    "\n",
    "    # 3. Dataset mô phỏng dữ liệu (Lima Filho et al., 2019)\n",
    "    print(\"Tạo bộ dữ liệu mô phỏng...\")\n",
    "    X_sim, y_sim = make_classification(\n",
    "        n_samples=4550,   \n",
    "        n_features=73,   \n",
    "        n_informative=60,\n",
    "        n_redundant=10,\n",
    "        n_clusters_per_class=2,\n",
    "        class_sep=0.9,    # Rất tách biệt để mô phỏng một môi trường kiểm soát\n",
    "        random_state=456\n",
    "    )\n",
    "    \n",
    "    sim_features = [f'network_metric_{i+1}' for i in range(73)]\n",
    "    X_sim_df = pd.DataFrame(X_sim, columns=sim_features)\n",
    "    y_sim_labels = ['Normal' if label == 0 else 'Attack' for label in y_sim]\n",
    "    \n",
    "    datasets['Simulated_Data'] = {\n",
    "        'X': X_sim_df,\n",
    "        'y': pd.Series(y_sim_labels),\n",
    "        'description': 'Dataset tổng hợp mô phỏng dữ liệu Lima Filho (73→20 đặc trưng)'\n",
    "    }\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Tạo các bộ dữ liệu tổng hợp\n",
    "synthetic_datasets = create_synthetic_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de06379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bổ sung giá trị NaN và vô cực để kiểm tra tiền xử lý...\n",
      "\n",
      "✅ 3 datasets tổng hợp được tạo thành công:\n",
      "   • NSL-KDD_2019: 15000 mẫu, 42 đặc trưng\n",
      "     Classes: {'Normal': 7500, 'Attack': 7500}\n",
      "     NaN values: 6296\n",
      "     Inf values: 630\n",
      "   • CICIDS_2017: 12000 mẫu, 68 đặc trưng\n",
      "     Classes: {'Normal': 7233, 'DoS': 2376, 'DDoS': 1791, 'Brute_Force': 600}\n",
      "     NaN values: 8150\n",
      "     Inf values: 816\n",
      "   • Simulated_Data: 4550 mẫu, 73 đặc trưng\n",
      "     Classes: {'Attack': 2279, 'Normal': 2271}\n",
      "     NaN values: 3319\n",
      "     Inf values: 332\n"
     ]
    }
   ],
   "source": [
    "# Bổ sung một vài giá trị có vấn đề để kiểm tra tiền xử lý\n",
    "print(\"Bổ sung giá trị NaN và vô cực để kiểm tra tiền xử lý...\")\n",
    "\n",
    "for dataset_name, dataset in synthetic_datasets.items():\n",
    "    # Tiêm 1-2% giá trị có vấn đề\n",
    "    n_samples, n_features = dataset['X'].shape\n",
    "    n_nan = int(0.01 * n_samples * n_features)\n",
    "\n",
    "    # Vị trí ngẫu nhiên cho NaN\n",
    "    nan_positions = np.random.choice(n_samples * n_features, n_nan, replace=False)\n",
    "    for pos in nan_positions:\n",
    "        row, col = divmod(pos, n_features)\n",
    "        dataset['X'].iloc[row, col] = np.nan\n",
    "\n",
    "    # Một vài giá trị vô cực\n",
    "    n_inf = max(1, n_nan // 10)\n",
    "    inf_positions = np.random.choice(n_samples * n_features, n_inf, replace=False)\n",
    "    for pos in inf_positions:\n",
    "        row, col = divmod(pos, n_features)\n",
    "        dataset['X'].iloc[row, col] = np.inf if np.random.random() > 0.5 else -np.inf\n",
    "\n",
    "print(f\"\\n✅ 3 datasets tổng hợp được tạo thành công:\")\n",
    "for name, dataset in synthetic_datasets.items():\n",
    "    print(f\"   • {name}: {dataset['X'].shape[0]} mẫu, {dataset['X'].shape[1]} đặc trưng\")\n",
    "    print(f\"     Classes: {dataset['y'].value_counts().to_dict()}\")\n",
    "    print(f\"     NaN values: {dataset['X'].isnull().sum().sum()}\")\n",
    "    print(f\"     Inf values: {np.isinf(dataset['X']).sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c030f",
   "metadata": {},
   "source": [
    "- Load data từ bộ dataset NSL-KDD 2019, CICIDS 2017 trên kaggle\n",
    "- Với bộ NSL-KDD 2019: gán tên cột, encode một số cột dữ liệu, gộp 2 bộ dữ liệu train, test\n",
    "- Với CICIDS 2017: gộp tất cả các bộ dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f803f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "  \n",
    "  datasets = {}\n",
    "  # Lấy dữ liệu bộ NSL-KDD 2019\n",
    "  # Download latest version\n",
    "  path_nslkdd = kagglehub.dataset_download(\"hassan06/nslkdd\")\n",
    "  train_data_KDD = pd.read_csv(f\"{path_nslkdd}/KDDTrain+.txt\", header=None)\n",
    "  test_data_KDD = pd.read_csv(f\"{path_nslkdd}/KDDTest+.txt\", header=None)\n",
    "  \n",
    "  # Define the list of column names based on the NSL-KDD dataset description\n",
    "  columns = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate', 'attack', 'level'\n",
    "  ]\n",
    "\n",
    "  # Assign the column names to the dataframe\n",
    "  train_data_KDD.columns = columns\n",
    "  test_data_KDD.columns = columns\n",
    "  \n",
    "  data_KDD = pd.concat([train_data_KDD, test_data_KDD], ignore_index=True)\n",
    "\n",
    "  X_KDD = data_KDD.drop(columns=['attack', 'level'])\n",
    "  for col in X_KDD.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_KDD[col] = le.fit_transform(X_KDD[col])\n",
    "  y_KDD = data_KDD['attack']\n",
    "\n",
    "  datasets['NSL-KDD'] = {\n",
    "        'X': X_KDD,\n",
    "        'y': y_KDD,\n",
    "        'description': 'NSL-KDD dataset từ Kaggle'\n",
    "    }\n",
    "\n",
    "  # Lấy dữ liệu bộ CICIDS 2017\n",
    "  # Download latest version\n",
    "  path_cicids = kagglehub.dataset_download(\"chethuhn/network-intrusion-dataset\")\n",
    "\n",
    "  # Get all CSV files in the directory\n",
    "  csv_files = glob.glob(os.path.join(path_cicids, \"*.csv\"))\n",
    "  # Read and concatenate all CSV files into a single DataFrame\n",
    "  df_2017 = pd.concat((pd.read_csv(file) for file in csv_files), ignore_index=True)\n",
    "  df_2017.columns = df_2017.columns.str.strip()\n",
    "  #print(df_2017['Label'].value_counts())\n",
    "  df_2017['Label'] = df_2017['Label'].str.strip()\n",
    "\n",
    "  X_cicids = df_2017.drop(columns=['Label'])\n",
    "  y_cicids = df_2017['Label']\n",
    "  datasets['CICIDS_2017'] = {\n",
    "        'X': X_cicids,\n",
    "        'y': y_cicids,\n",
    "        'description': 'CICIDS 2017 dataset từ Kaggle'\n",
    "    }\n",
    "  return datasets\n",
    "datasets = load_dataset()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92816d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NSL-KDD': {'X':         duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
      "0              0              1       20     9        491          0     0   \n",
      "1              0              2       44     9        146          0     0   \n",
      "2              0              1       49     5          0          0     0   \n",
      "3              0              1       24     9        232       8153     0   \n",
      "4              0              1       24     9        199        420     0   \n",
      "...          ...            ...      ...   ...        ...        ...   ...   \n",
      "148512         0              1       54     9        794        333     0   \n",
      "148513         0              1       24     9        317        938     0   \n",
      "148514         0              1       24     9      54540       8314     0   \n",
      "148515         0              2       12     9         42         42     0   \n",
      "148516         0              1       57     1          0          0     0   \n",
      "\n",
      "        wrong_fragment  urgent  hot  ...  dst_host_count  dst_host_srv_count  \\\n",
      "0                    0       0    0  ...             150                  25   \n",
      "1                    0       0    0  ...             255                   1   \n",
      "2                    0       0    0  ...             255                  26   \n",
      "3                    0       0    0  ...              30                 255   \n",
      "4                    0       0    0  ...             255                 255   \n",
      "...                ...     ...  ...  ...             ...                 ...   \n",
      "148512               0       0    0  ...             100                 141   \n",
      "148513               0       0    0  ...             197                 255   \n",
      "148514               0       0    2  ...             255                 255   \n",
      "148515               0       0    0  ...             255                 252   \n",
      "148516               0       0    0  ...             255                  21   \n",
      "\n",
      "        dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                         0.17                    0.03   \n",
      "1                         0.00                    0.60   \n",
      "2                         0.10                    0.05   \n",
      "3                         1.00                    0.00   \n",
      "4                         1.00                    0.00   \n",
      "...                        ...                     ...   \n",
      "148512                    0.72                    0.06   \n",
      "148513                    1.00                    0.00   \n",
      "148514                    1.00                    0.00   \n",
      "148515                    0.99                    0.01   \n",
      "148516                    0.08                    0.03   \n",
      "\n",
      "        dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                              0.17                         0.00   \n",
      "1                              0.88                         0.00   \n",
      "2                              0.00                         0.00   \n",
      "3                              0.03                         0.04   \n",
      "4                              0.00                         0.00   \n",
      "...                             ...                          ...   \n",
      "148512                         0.01                         0.01   \n",
      "148513                         0.01                         0.01   \n",
      "148514                         0.00                         0.00   \n",
      "148515                         0.00                         0.00   \n",
      "148516                         0.00                         0.00   \n",
      "\n",
      "        dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0                       0.00                      0.00                  0.05   \n",
      "1                       0.00                      0.00                  0.00   \n",
      "2                       1.00                      1.00                  0.00   \n",
      "3                       0.03                      0.01                  0.00   \n",
      "4                       0.00                      0.00                  0.00   \n",
      "...                      ...                       ...                   ...   \n",
      "148512                  0.01                      0.00                  0.00   \n",
      "148513                  0.01                      0.00                  0.00   \n",
      "148514                  0.00                      0.00                  0.07   \n",
      "148515                  0.00                      0.00                  0.00   \n",
      "148516                  0.00                      0.00                  0.44   \n",
      "\n",
      "        dst_host_srv_rerror_rate  \n",
      "0                           0.00  \n",
      "1                           0.00  \n",
      "2                           0.00  \n",
      "3                           0.01  \n",
      "4                           0.00  \n",
      "...                          ...  \n",
      "148512                      0.00  \n",
      "148513                      0.00  \n",
      "148514                      0.07  \n",
      "148515                      0.00  \n",
      "148516                      1.00  \n",
      "\n",
      "[148517 rows x 41 columns], 'y': 0          normal\n",
      "1          normal\n",
      "2         neptune\n",
      "3          normal\n",
      "4          normal\n",
      "           ...   \n",
      "148512     normal\n",
      "148513     normal\n",
      "148514       back\n",
      "148515     normal\n",
      "148516      mscan\n",
      "Name: attack, Length: 148517, dtype: object, 'description': 'NSL-KDD dataset từ Kaggle'}, 'CICIDS_2017': {'X':          Destination Port  Flow Duration  Total Fwd Packets  \\\n",
      "0                   54865              3                  2   \n",
      "1                   55054            109                  1   \n",
      "2                   55055             52                  1   \n",
      "3                   46236             34                  1   \n",
      "4                   54863              3                  2   \n",
      "...                   ...            ...                ...   \n",
      "2830738                53          32215                  4   \n",
      "2830739                53            324                  2   \n",
      "2830740             58030             82                  2   \n",
      "2830741                53        1048635                  6   \n",
      "2830742                53          94939                  4   \n",
      "\n",
      "         Total Backward Packets  Total Length of Fwd Packets  \\\n",
      "0                             0                           12   \n",
      "1                             1                            6   \n",
      "2                             1                            6   \n",
      "3                             1                            6   \n",
      "4                             0                           12   \n",
      "...                         ...                          ...   \n",
      "2830738                       2                          112   \n",
      "2830739                       2                           84   \n",
      "2830740                       1                           31   \n",
      "2830741                       2                          192   \n",
      "2830742                       2                          188   \n",
      "\n",
      "         Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
      "0                                  0                      6   \n",
      "1                                  6                      6   \n",
      "2                                  6                      6   \n",
      "3                                  6                      6   \n",
      "4                                  0                      6   \n",
      "...                              ...                    ...   \n",
      "2830738                          152                     28   \n",
      "2830739                          362                     42   \n",
      "2830740                            6                     31   \n",
      "2830741                          256                     32   \n",
      "2830742                          226                     47   \n",
      "\n",
      "         Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
      "0                            6                     6.0                0.00000   \n",
      "1                            6                     6.0                0.00000   \n",
      "2                            6                     6.0                0.00000   \n",
      "3                            6                     6.0                0.00000   \n",
      "4                            6                     6.0                0.00000   \n",
      "...                        ...                     ...                    ...   \n",
      "2830738                     28                    28.0                0.00000   \n",
      "2830739                     42                    42.0                0.00000   \n",
      "2830740                      0                    15.5               21.92031   \n",
      "2830741                     32                    32.0                0.00000   \n",
      "2830742                     47                    47.0                0.00000   \n",
      "\n",
      "         ...  act_data_pkt_fwd  min_seg_size_forward  Active Mean  Active Std  \\\n",
      "0        ...                 1                    20          0.0         0.0   \n",
      "1        ...                 0                    20          0.0         0.0   \n",
      "2        ...                 0                    20          0.0         0.0   \n",
      "3        ...                 0                    20          0.0         0.0   \n",
      "4        ...                 1                    20          0.0         0.0   \n",
      "...      ...               ...                   ...          ...         ...   \n",
      "2830738  ...                 3                    20          0.0         0.0   \n",
      "2830739  ...                 1                    20          0.0         0.0   \n",
      "2830740  ...                 0                    32          0.0         0.0   \n",
      "2830741  ...                 5                    20          0.0         0.0   \n",
      "2830742  ...                 3                    20          0.0         0.0   \n",
      "\n",
      "         Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  \n",
      "0                 0           0        0.0       0.0         0         0  \n",
      "1                 0           0        0.0       0.0         0         0  \n",
      "2                 0           0        0.0       0.0         0         0  \n",
      "3                 0           0        0.0       0.0         0         0  \n",
      "4                 0           0        0.0       0.0         0         0  \n",
      "...             ...         ...        ...       ...       ...       ...  \n",
      "2830738           0           0        0.0       0.0         0         0  \n",
      "2830739           0           0        0.0       0.0         0         0  \n",
      "2830740           0           0        0.0       0.0         0         0  \n",
      "2830741           0           0        0.0       0.0         0         0  \n",
      "2830742           0           0        0.0       0.0         0         0  \n",
      "\n",
      "[2830743 rows x 78 columns], 'y': 0          BENIGN\n",
      "1          BENIGN\n",
      "2          BENIGN\n",
      "3          BENIGN\n",
      "4          BENIGN\n",
      "            ...  \n",
      "2830738    BENIGN\n",
      "2830739    BENIGN\n",
      "2830740    BENIGN\n",
      "2830741    BENIGN\n",
      "2830742    BENIGN\n",
      "Name: Label, Length: 2830743, dtype: object, 'description': 'CICIDS 2017 dataset từ Kaggle'}}\n"
     ]
    }
   ],
   "source": [
    "print((datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10785da5",
   "metadata": {},
   "source": [
    "Implement systematic evaluation with time/accuracy measurement \n",
    "- Triển khai đánh giá hệ thống vá đo thời gian/độ chính xác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4639915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tạo các bộ dữ liệu tổng hợp dựa trên bài báo...\n",
      "\n",
      "Tạo bộ dữ liệu NSL-KDD 2019...\n",
      "Tạo bộ dữ liệu tổng hợp CICIDS 2017...\n",
      "Tạo bộ dữ liệu mô phỏng...\n",
      "Bắt đầu đánh giá\n",
      "================================================================================\n",
      "\n",
      "Đánh giá bộ dữ liệu: NSL-KDD_2019\n",
      "   Dataset tổng hợp mô phỏng NSL-KDD 2019 (42→21 đặc trưng)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Tiền xử lý dữ liệu NSL-KDD_2019...\n",
      "   Kích thước ban đầu: (15000, 42)\n",
      "   Sau khi làm sạch: (15000, 42)\n",
      "Tiền xử lý hoàn tất - shape cuối cùng: (15000, 42)\n",
      "\n",
      "   Division:\n",
      "      Train: 12000 mẫu\n",
      "      Test: 3000 mẫu\n",
      "\n",
      "Áp dụng các kỹ thuật giảm chiều dữ liệu...\n",
      "PCA: 42 → 21 features\n",
      "Feature Importance: tự động chọn các features tốt nhất\n",
      "Univariate Selection: SelectKBest vs chi2\n",
      "Hoàn thành giảm chiều dữ liệu\n",
      "\n",
      "   ĐÁNH GIÁ CÁC KẾT HỢP ML + Feature Selection:\n",
      "   Thuật toán      Phương pháp giảm chiều Độ chính xác (%) Thời gian (ms) Số features\n",
      "   --------------- ------------------ ------------ ---------- --------\n",
      "\n",
      "   BASELINE (không giảm chiều):\n",
      "   KNN             No_Reduction       97.00        335.4      42      \n",
      "   AdaBoost        No_Reduction       79.43        2600.1     42      \n",
      "   RandomForest    No_Reduction       93.60        4682.3     42      \n",
      "   SVM             No_Reduction       98.57        1098.3     42      \n",
      "\n",
      "   SAU KHI GIẢM CHIỀU:\n",
      "\n",
      "   🔹 PCA:\n",
      "     KNN             PCA                89.40        33.0       21      \n",
      "     AdaBoost        PCA                77.53        1365.5     21      \n",
      "     RandomForest    PCA                87.47        3285.2     21      \n",
      "     SVM             PCA                93.03        1396.5     21      \n",
      "\n",
      "   🔹 Feature_Importance:\n",
      "     KNN             Feature_Importance 86.93        486.0      15      \n",
      "     AdaBoost        Feature_Importance 76.63        965.7      15      \n",
      "     RandomForest    Feature_Importance 86.17        2419.6     15      \n",
      "     SVM             Feature_Importance 90.40        1450.7     15      \n",
      "\n",
      "   🔹 Univariate_Selection:\n",
      "     KNN             Univariate_Selection 88.80        79.5       21      \n",
      "     AdaBoost        Univariate_Selection 75.27        1335.4     21      \n",
      "     RandomForest    Univariate_Selection 86.80        3134.9     21      \n",
      "     SVM             Univariate_Selection 90.70        1265.9     21      \n",
      "\n",
      "   Sự kết hợp tốt nhất NSL-KDD_2019:\n",
      "      SVM + No_Reduction\n",
      "      Độ chính xác: 98.57%\n",
      "      Thời gian: 1098.3 ms\n",
      "      Số đặc điểm: 42\n",
      "\n",
      "Đánh giá bộ dữ liệu: CICIDS_2017\n",
      "   Dataset tổng hợp mô phỏng CICIDS 2017 (68→23 đặc trưng)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Tiền xử lý dữ liệu CICIDS_2017...\n",
      "   Kích thước ban đầu: (12000, 68)\n",
      "   Sau khi làm sạch: (12000, 68)\n",
      "Tiền xử lý hoàn tất - shape cuối cùng: (12000, 68)\n",
      "\n",
      "   Division:\n",
      "      Train: 9600 mẫu\n",
      "      Test: 2400 mẫu\n",
      "\n",
      "Áp dụng các kỹ thuật giảm chiều dữ liệu...\n",
      "PCA: 68 → 34 features\n",
      "Feature Importance: tự động chọn các features tốt nhất\n",
      "Univariate Selection: SelectKBest vs chi2\n",
      "Hoàn thành giảm chiều dữ liệu\n",
      "\n",
      "   ĐÁNH GIÁ CÁC KẾT HỢP ML + Feature Selection:\n",
      "   Thuật toán      Phương pháp giảm chiều Độ chính xác (%) Thời gian (ms) Số features\n",
      "   --------------- ------------------ ------------ ---------- --------\n",
      "\n",
      "   BASELINE (không giảm chiều):\n",
      "   KNN             No_Reduction       45.79        102.7      68      \n",
      "   AdaBoost        No_Reduction       59.83        3311.2     68      \n",
      "   RandomForest    No_Reduction       60.04        8503.8     68      \n",
      "   SVM             No_Reduction       60.04        5615.5     68      \n",
      "\n",
      "   SAU KHI GIẢM CHIỀU:\n",
      "\n",
      "   🔹 PCA:\n",
      "     KNN             PCA                46.04        15.6       34      \n",
      "     AdaBoost        PCA                59.79        1750.4     34      \n",
      "     RandomForest    PCA                60.04        5485.4     34      \n",
      "     SVM             PCA                60.04        4497.9     34      \n",
      "\n",
      "   🔹 Feature_Importance:\n",
      "     KNN             Feature_Importance 46.46        69.7       34      \n",
      "     AdaBoost        Feature_Importance 60.00        1719.4     34      \n",
      "     RandomForest    Feature_Importance 60.00        5241.1     34      \n",
      "     SVM             Feature_Importance 60.04        4330.2     34      \n",
      "\n",
      "   🔹 Univariate_Selection:\n",
      "     KNN             Univariate_Selection 46.04        90.4       34      \n",
      "     AdaBoost        Univariate_Selection 59.33        1718.9     34      \n",
      "     RandomForest    Univariate_Selection 59.92        5216.3     34      \n",
      "     SVM             Univariate_Selection 60.04        4317.7     34      \n",
      "\n",
      "   Sự kết hợp tốt nhất CICIDS_2017:\n",
      "      RandomForest + No_Reduction\n",
      "      Độ chính xác: 60.04%\n",
      "      Thời gian: 8503.8 ms\n",
      "      Số đặc điểm: 68\n",
      "\n",
      "Đánh giá bộ dữ liệu: Simulated_Data\n",
      "   Dataset tổng hợp mô phỏng dữ liệu Lima Filho (73→20 đặc trưng)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Tiền xử lý dữ liệu Simulated_Data...\n",
      "   Kích thước ban đầu: (4550, 73)\n",
      "   Sau khi làm sạch: (4550, 73)\n",
      "Tiền xử lý hoàn tất - shape cuối cùng: (4550, 73)\n",
      "\n",
      "   Division:\n",
      "      Train: 3640 mẫu\n",
      "      Test: 910 mẫu\n",
      "\n",
      "Áp dụng các kỹ thuật giảm chiều dữ liệu...\n",
      "PCA: 73 → 36 features\n",
      "Feature Importance: tự động chọn các features tốt nhất\n",
      "Univariate Selection: SelectKBest vs chi2\n",
      "Hoàn thành giảm chiều dữ liệu\n",
      "\n",
      "   ĐÁNH GIÁ CÁC KẾT HỢP ML + Feature Selection:\n",
      "   Thuật toán      Phương pháp giảm chiều Độ chính xác (%) Thời gian (ms) Số features\n",
      "   --------------- ------------------ ------------ ---------- --------\n",
      "\n",
      "   BASELINE (không giảm chiều):\n",
      "   KNN             No_Reduction       97.03        50.8       73      \n",
      "   AdaBoost        No_Reduction       74.95        1297.7     73      \n",
      "   RandomForest    No_Reduction       91.32        1598.6     73      \n",
      "   SVM             No_Reduction       98.57        284.2      73      \n",
      "\n",
      "   SAU KHI GIẢM CHIỀU:\n",
      "\n",
      "   🔹 PCA:\n",
      "     KNN             PCA                88.46        31.3       36      \n",
      "     AdaBoost        PCA                74.95        665.9      36      \n",
      "     RandomForest    PCA                86.92        1271.7     36      \n",
      "     SVM             PCA                95.82        201.0      36      \n",
      "\n",
      "   🔹 Feature_Importance:\n",
      "     KNN             Feature_Importance 87.69        50.2       29      \n",
      "     AdaBoost        Feature_Importance 74.73        550.3      29      \n",
      "     RandomForest    Feature_Importance 84.07        1016.0     29      \n",
      "     SVM             Feature_Importance 91.87        185.5      29      \n",
      "\n",
      "   🔹 Univariate_Selection:\n",
      "     KNN             Univariate_Selection 87.58        49.6       36      \n",
      "     AdaBoost        Univariate_Selection 71.32        661.5      36      \n",
      "     RandomForest    Univariate_Selection 74.95        1203.2     36      \n",
      "     SVM             Univariate_Selection 91.54        188.6      36      \n",
      "\n",
      "   Sự kết hợp tốt nhất Simulated_Data:\n",
      "      SVM + No_Reduction\n",
      "      Độ chính xác: 98.57%\n",
      "      Thời gian: 284.2 ms\n",
      "      Số đặc điểm: 73\n"
     ]
    }
   ],
   "source": [
    "def run_complete_evaluation(classifier, datasets):\n",
    "    \"\"\"\n",
    "    Thực hiện đánh giá đầy đủ theo phương pháp của bài viết:\n",
    "    - Kiểm tra các thuật toán 4 ml với 3 kỹ thuật lựa chọn tính năng\n",
    "    - Đo lường thời gian thực hiện và độ chính xác\n",
    "    - Tạo bảng kết quả\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Bắt đầu đánh giá\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "\n",
    "    for dataset_name, dataset_info in datasets.items():\n",
    "        print(f\"\\nĐánh giá bộ dữ liệu: {dataset_name}\")\n",
    "        print(f\"   {dataset_info['description']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        X, y = dataset_info['X'], dataset_info['y']\n",
    "        \n",
    "        # 1. Tiền xử lý\n",
    "        X_processed, y_processed = classifier.preprocess_data(X, y, dataset_name)\n",
    "\n",
    "        # 2. Division train/test (80/20)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_processed, y_processed, test_size=0.2, random_state=42, stratify=y_processed\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n   Division:\")\n",
    "        print(f\"      Train: {X_train.shape[0]} mẫu\")\n",
    "        print(f\"      Test: {X_test.shape[0]} mẫu\")\n",
    "        \n",
    "        # 3. Áp dụng các kỹ thuật lựa giảm chiều\n",
    "        feature_selection_results = classifier.apply_feature_selection(\n",
    "            X_train, X_test, y_train\n",
    "        )\n",
    "        \n",
    "        # 4. Đánh giá kết hợp ML + Feature Selection\n",
    "        dataset_results = {}\n",
    "        \n",
    "        print(f\"\\n   ĐÁNH GIÁ CÁC KẾT HỢP ML + Feature Selection:\")\n",
    "        print(f\"   {'Thuật toán':<15} {'Phương pháp giảm chiều':<18} {'Độ chính xác (%)':<12} {'Thời gian (ms)':<10} {'Số features':<8}\")\n",
    "        print(f\"   {'-'*15} {'-'*18} {'-'*12} {'-'*10} {'-'*8}\")\n",
    "        \n",
    "        # Đánh giá trước khi giảm chiều (baseline)\n",
    "        print(f\"\\n   BASELINE (không giảm chiều):\")\n",
    "        for ml_name in classifier.ml_algorithms.keys():\n",
    "            result = classifier.evaluate_model_combination(\n",
    "                X_train, X_test, y_train, y_test, ml_name, \"No_Reduction\", dataset_name\n",
    "            )\n",
    "            \n",
    "            dataset_results[f\"{ml_name}_No_Reduction\"] = {\n",
    "                'ml_algorithm': ml_name,\n",
    "                'feature_method': 'No_Reduction',\n",
    "                'accuracy': result['accuracy'],\n",
    "                'time_ms': result['total_time_ms'],\n",
    "                'n_features': X_train.shape[1]\n",
    "            }\n",
    "            \n",
    "            print(f\"   {ml_name:<15} {'No_Reduction':<18} {result['accuracy']:<12.2f} {result['total_time_ms']:<10.1f} {X_train.shape[1]:<8}\")\n",
    "        \n",
    "        # đánh giá khi giảm chiều\n",
    "        print(f\"\\n   SAU KHI GIẢM CHIỀU:\")\n",
    "        for feature_method, feature_data in feature_selection_results.items():\n",
    "            print(f\"\\n   🔹 {feature_method}:\")\n",
    "            \n",
    "            X_train_reduced = feature_data['X_train']\n",
    "            X_test_reduced = feature_data['X_test']\n",
    "            n_features = feature_data['n_features']\n",
    "            \n",
    "            for ml_name in classifier.ml_algorithms.keys():\n",
    "                result = classifier.evaluate_model_combination(\n",
    "                    X_train_reduced, X_test_reduced, y_train, y_test, \n",
    "                    ml_name, feature_method, dataset_name\n",
    "                )\n",
    "                \n",
    "                key = f\"{ml_name}_{feature_method}\"\n",
    "                dataset_results[key] = {\n",
    "                    'ml_algorithm': ml_name,\n",
    "                    'feature_method': feature_method,\n",
    "                    'accuracy': result['accuracy'],\n",
    "                    'time_ms': result['total_time_ms'],\n",
    "                    'n_features': n_features\n",
    "                }\n",
    "                \n",
    "                print(f\"     {ml_name:<15} {feature_method:<18} {result['accuracy']:<12.2f} {result['total_time_ms']:<10.1f} {n_features:<8}\")\n",
    "        \n",
    "        all_results[dataset_name] = dataset_results\n",
    "        \n",
    "        # Xác định sự kết hợp tốt nhất cho bộ dữ liệu này\n",
    "        best_combo = max(dataset_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        print(f\"\\n   Sự kết hợp tốt nhất {dataset_name}:\")\n",
    "        print(f\"      {best_combo[1]['ml_algorithm']} + {best_combo[1]['feature_method']}\")\n",
    "        print(f\"      Độ chính xác: {best_combo[1]['accuracy']:.2f}%\")\n",
    "        print(f\"      Thời gian: {best_combo[1]['time_ms']:.1f} ms\")\n",
    "        print(f\"      Số đặc điểm: {best_combo[1]['n_features']}\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# Khởi tạo trình phân loại và thực hiện đánh giá\n",
    "classifier = DoSDDoSClassifier()\n",
    "#evaluation_results = run_complete_evaluation(classifier, load_dataset())\n",
    "evaluation_results = run_complete_evaluation(classifier, create_synthetic_datasets())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a8075a",
   "metadata": {},
   "source": [
    "- Tạo bảng kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2910a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TẠO CÁC BẢNG KẾT QUẢ\n",
      "================================================================================\n",
      "\n",
      "BẢNG KẾT QUẢ - NSL-KDD_2019\n",
      "----------------------------------------------------------------------\n",
      "Thuật toán ML Phương pháp giảm chiều Độ chính xác (%) Thời gian (ms)  Số features\n",
      "          SVM           No_Reduction            98.57         1098.3           42\n",
      "          KNN           No_Reduction            97.00          335.4           42\n",
      " RandomForest           No_Reduction            93.60         4682.3           42\n",
      "          SVM                    PCA            93.03         1396.5           21\n",
      "          SVM   Univariate_Selection            90.70         1265.9           21\n",
      "          SVM     Feature_Importance            90.40         1450.7           15\n",
      "          KNN                    PCA            89.40           33.0           21\n",
      "          KNN   Univariate_Selection            88.80           79.5           21\n",
      " RandomForest                    PCA            87.47         3285.2           21\n",
      "          KNN     Feature_Importance            86.93          486.0           15\n",
      " RandomForest   Univariate_Selection            86.80         3134.9           21\n",
      " RandomForest     Feature_Importance            86.17         2419.6           15\n",
      "     AdaBoost           No_Reduction            79.43         2600.1           42\n",
      "     AdaBoost                    PCA            77.53         1365.5           21\n",
      "     AdaBoost     Feature_Importance            76.63          965.7           15\n",
      "     AdaBoost   Univariate_Selection            75.27         1335.4           21\n",
      "\n",
      "  KẾT QUẢ TỐT NHẤT:\n",
      "      SVM + No_Reduction\n",
      "      Độ chính xác: 98.57%\n",
      "      Thời gian: 1098.3 ms\n",
      "      Số features: 42\n",
      "\n",
      "  PHÂN TÍCH CẢI THIỆN:\n",
      "      Giảm thời gian trung bình: 34.2%\n",
      "      Thời gian trung bình baseline: 2179.0 ms\n",
      "      Thời gian trung bình với giảm chiều: 1434.8 ms\n",
      "\n",
      "BẢNG KẾT QUẢ - CICIDS_2017\n",
      "----------------------------------------------------------------------\n",
      "Thuật toán ML Phương pháp giảm chiều Độ chính xác (%) Thời gian (ms)  Số features\n",
      " RandomForest           No_Reduction            60.04         8503.8           68\n",
      "          SVM           No_Reduction            60.04         5615.5           68\n",
      " RandomForest                    PCA            60.04         5485.4           34\n",
      "          SVM                    PCA            60.04         4497.9           34\n",
      "          SVM     Feature_Importance            60.04         4330.2           34\n",
      "          SVM   Univariate_Selection            60.04         4317.7           34\n",
      "     AdaBoost     Feature_Importance            60.00         1719.4           34\n",
      " RandomForest     Feature_Importance            60.00         5241.1           34\n",
      " RandomForest   Univariate_Selection            59.92         5216.3           34\n",
      "     AdaBoost           No_Reduction            59.83         3311.2           68\n",
      "     AdaBoost                    PCA            59.79         1750.4           34\n",
      "     AdaBoost   Univariate_Selection            59.33         1718.9           34\n",
      "          KNN     Feature_Importance            46.46           69.7           34\n",
      "          KNN                    PCA            46.04           15.6           34\n",
      "          KNN   Univariate_Selection            46.04           90.4           34\n",
      "          KNN           No_Reduction            45.79          102.7           68\n",
      "\n",
      "  KẾT QUẢ TỐT NHẤT:\n",
      "      RandomForest + No_Reduction\n",
      "      Độ chính xác: 60.04%\n",
      "      Thời gian: 8503.8 ms\n",
      "      Số features: 68\n",
      "\n",
      "  PHÂN TÍCH CẢI THIỆN:\n",
      "      Giảm thời gian trung bình: 34.5%\n",
      "      Thời gian trung bình baseline: 4383.3 ms\n",
      "      Thời gian trung bình với giảm chiều: 2871.1 ms\n",
      "\n",
      "BẢNG KẾT QUẢ - Simulated_Data\n",
      "----------------------------------------------------------------------\n",
      "Thuật toán ML Phương pháp giảm chiều Độ chính xác (%) Thời gian (ms)  Số features\n",
      "          SVM           No_Reduction            98.57          284.2           73\n",
      "          KNN           No_Reduction            97.03           50.8           73\n",
      "          SVM                    PCA            95.82          201.0           36\n",
      "          SVM     Feature_Importance            91.87          185.5           29\n",
      "          SVM   Univariate_Selection            91.54          188.6           36\n",
      " RandomForest           No_Reduction            91.32         1598.6           73\n",
      "          KNN                    PCA            88.46           31.3           36\n",
      "          KNN     Feature_Importance            87.69           50.2           29\n",
      "          KNN   Univariate_Selection            87.58           49.6           36\n",
      " RandomForest                    PCA            86.92         1271.7           36\n",
      " RandomForest     Feature_Importance            84.07         1016.0           29\n",
      "     AdaBoost           No_Reduction            74.95         1297.7           73\n",
      "     AdaBoost                    PCA            74.95          665.9           36\n",
      " RandomForest   Univariate_Selection            74.95         1203.2           36\n",
      "     AdaBoost     Feature_Importance            74.73          550.3           29\n",
      "     AdaBoost   Univariate_Selection            71.32          661.5           36\n",
      "\n",
      "  KẾT QUẢ TỐT NHẤT:\n",
      "      SVM + No_Reduction\n",
      "      Độ chính xác: 98.57%\n",
      "      Thời gian: 284.2 ms\n",
      "      Số features: 73\n",
      "\n",
      "  PHÂN TÍCH CẢI THIỆN:\n",
      "      Giảm thời gian trung bình: 37.3%\n",
      "      Thời gian trung bình baseline: 807.8 ms\n",
      "      Thời gian trung bình với giảm chiều: 506.2 ms\n"
     ]
    }
   ],
   "source": [
    "def create_results_tables(evaluation_results):\n",
    "    \"\"\"\n",
    "    tạo bảng kết quả\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"TẠO CÁC BẢNG KẾT QUẢ\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for dataset_name, results in evaluation_results.items():\n",
    "        print(f\"\\nBẢNG KẾT QUẢ - {dataset_name}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        # tạo 1 DataFrame để hiển thị bảng\n",
    "        table_data = []\n",
    "        \n",
    "        for combo_name, combo_results in results.items():\n",
    "            ml_algo = combo_results['ml_algorithm']\n",
    "            feature_method = combo_results['feature_method']\n",
    "            accuracy = combo_results['accuracy']\n",
    "            time_ms = combo_results['time_ms']\n",
    "            n_features = combo_results['n_features']\n",
    "            \n",
    "            table_data.append({\n",
    "                'Thuật toán ML': ml_algo,\n",
    "                'Phương pháp giảm chiều': feature_method,\n",
    "                'Độ chính xác (%)': f\"{accuracy:.2f}\",\n",
    "                'Thời gian (ms)': f\"{time_ms:.1f}\",\n",
    "                'Số features': n_features\n",
    "            })\n",
    "        \n",
    "        df_results = pd.DataFrame(table_data)\n",
    "        \n",
    "        # Sắp xếp bằng cách giảm độ chính xác\n",
    "        df_results = df_results.sort_values('Độ chính xác (%)', ascending=False)\n",
    "\n",
    "        print(df_results.to_string(index=False))\n",
    "\n",
    "        # Thống kê bổ sung\n",
    "        best_accuracy = df_results.iloc[0]\n",
    "        print(f\"\\n  KẾT QUẢ TỐT NHẤT:\")\n",
    "        print(f\"      {best_accuracy['Thuật toán ML']} + {best_accuracy['Phương pháp giảm chiều']}\")\n",
    "        print(f\"      Độ chính xác: {best_accuracy['Độ chính xác (%)']}%\")\n",
    "        print(f\"      Thời gian: {best_accuracy['Thời gian (ms)']} ms\")\n",
    "        print(f\"      Số features: {best_accuracy['Số features']}\")\n",
    "\n",
    "        # Phân tích cải thiện thời gian so với độ chính xác\n",
    "        baseline_results = df_results[df_results['Phương pháp giảm chiều'] == 'No_Reduction']\n",
    "        reduced_results = df_results[df_results['Phương pháp giảm chiều'] != 'No_Reduction']\n",
    "\n",
    "        if not baseline_results.empty and not reduced_results.empty:\n",
    "            avg_baseline_time = baseline_results['Thời gian (ms)'].str.replace(' ms', '').astype(float).mean()\n",
    "            avg_reduced_time = reduced_results['Thời gian (ms)'].str.replace(' ms', '').astype(float).mean()\n",
    "\n",
    "            time_improvement = ((avg_baseline_time - avg_reduced_time) / avg_baseline_time) * 100\n",
    "\n",
    "            print(f\"\\n  PHÂN TÍCH CẢI THIỆN:\")\n",
    "            print(f\"      Giảm thời gian trung bình: {time_improvement:.1f}%\")\n",
    "            print(f\"      Thời gian trung bình baseline: {avg_baseline_time:.1f} ms\")\n",
    "            print(f\"      Thời gian trung bình với giảm chiều: {avg_reduced_time:.1f} ms\")\n",
    "\n",
    "# Tạo bảng kết quả\n",
    "create_results_tables(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c4ecea",
   "metadata": {},
   "source": [
    "Create performance visualizations and comparisons\n",
    "- Tạo biểu đồ so sánh hiệu năng"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
